{"pages":[{"title":"","text":"关于我","link":"/about/index.html"}],"posts":[{"title":"Hexo-Icarus主题去除谷歌字体，提升加载速度","text":"背景在使用github pages服务搭建Hexo博客的时候使用icarus作为主题，使用hexo generate和hexo deploy命令生成并部署后，在访问主页的时候发现加载速度特别慢，通过浏览器调试模式发现了加载速度慢的原因从调试截图中可以看到，请求中有一个谷歌字体的失败请求，因为谷歌被墙的原因，国内无法加载这个字体，所以导致整个页面的请求都在等待这个请求直至请求失败，页面最终加载成功 通过关键字翻阅icarus主题的文件，在themes\\icarus\\layout\\common\\head.ejs文件查找到了字体引用的代码 12345678910111213141516171819202122232425262728293031323334353637383940&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;&lt;%= page_title() %&gt;&lt;/title&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=1&quot; /&gt;&lt;%- meta() %&gt;&lt;% if (has_config(&apos;open_graph&apos;)) { %&gt; &lt;%- open_graph({ twitter_id: get_config(&apos;open_graph.twitter_id&apos;), twitter_site: get_config(&apos;open_graph.twitter_site&apos;), google_plus: get_config(&apos;open_graph.google_plus&apos;), fb_admins: get_config(&apos;open_graph.fb_admins&apos;), fb_app_id: get_config(&apos;open_graph.fb_app_id&apos;), image: get_og_image(page) }) %&gt;&lt;% } %&gt;&lt;% if (has_config(&apos;canonical_url&apos;)) { %&gt;&lt;link rel=&quot;canonical&quot; href=&quot;&lt;%- get_config(&apos;canonical_url&apos;) %&gt;&quot; /&gt;&lt;% } %&gt;&lt;% if (has_config(&apos;rss&apos;)) { %&gt;&lt;link rel=&quot;alternative&quot; href=&quot;&lt;%- get_config(&apos;rss&apos;) %&gt;&quot; title=&quot;&lt;%= get_config(&apos;title&apos;) %&gt;&quot; type=&quot;application/atom+xml&quot;&gt;&lt;% } %&gt;&lt;% if (has_config(&apos;favicon&apos;)) { %&gt;&lt;link rel=&quot;icon&quot; href=&quot;&lt;%- url_for(get_config(&apos;favicon&apos;)) %&gt;&quot;&gt;&lt;% } %&gt;&lt;%- _css(cdn(&apos;bulma&apos;, &apos;0.7.2&apos;, &apos;css/bulma.css&apos;)) %&gt;&lt;%- _css(iconcdn()) %&gt;&lt;%- _css(fontcdn(&apos;Ubuntu:400,600|Source+Code+Pro&apos;)) %&gt;&lt;%- _css(cdn(&apos;highlight.js&apos;, &apos;9.12.0&apos;, &apos;styles/&apos; + get_config(&apos;article.highlight&apos;) + &apos;.css&apos;)) %&gt;&lt;% if (has_config(&apos;plugins&apos;)) { %&gt; &lt;% for (let plugin in get_config(&apos;plugins&apos;)) { %&gt; &lt;%- partial(&apos;plugin/&apos; + plugin, { head: true, plugin: get_config(&apos;plugins&apos;)[plugin] }) %&gt; &lt;% } %&gt;&lt;% } %&gt;&lt;%- _css(&apos;css/style&apos;) %&gt; 删除第31行代码，重新生成部署 &lt;%- _css(fontcdn(&apos;Ubuntu:400,600|Source+Code+Pro&apos;)) %&gt;","link":"/2019/07/09/Hexo-Icarus主题去除谷歌字体，提升加载速度/"},{"title":"Hexo-Icarus主题引入live2d插件和解决配置冲突","text":"前言搭建好自己Hexo博客，大家都会绞尽脑汁去装修自己的博客页面，作为二次元的小萌希望能在自己的博客上放上自己喜欢的动漫人物或者看板小挂件。在网上看了很多大牛分享的Hexo博客搭建教程中都有live2d插件身影出现。 live2d是一种应用于电子游戏的绘图渲染技术，通过一系列的连续图像和人物建模来生成一种类似三维模型的二维图像，现在广泛应用于手游，桌面动态壁纸等领域，各大博客系统也都推出或是第三方插件适配live2d。 插件EYHN/hexo-helper-live2d 模型下载 模型预览 对live2d插件感兴趣的朋友可以去的github上看看，readme.md有中文文档，遇到问题可以在项目里的issue有没有人遇到跟你一样的问题，也可以提交一个issue，作者或者各位大牛会出方案解决你的问题。 安装进入hexo博客根目录，打开gitbash或者cmd等命令行工具输入以下命令安装hexo-helper-live2d插件： npm install --save hexo-helper-live2d配置插件的配置可以直接配置在Hexo根目录下的配置文件_config.yml中，也可以配置在主题目录themes目录下的配置文件_config.yml文件中，一般推荐配置在Hexo根目录下的配置文件中，防止更换主题后live2d失效。但是如果你使用的主题是icarus,那么只能够配置在Hexo根目录下的配置文件中，不能配置到icarus主题目录下的配置文件中。 当你把插件的配置放在icarus主题的配置文件时，无论你修改插件的哪个参数都不会起作用，live2d插件虽然启动，但是却永远是shizuku看板娘，模型、位置、大小等都不能配置。 通用配置：​ live2d: enable: true # enable: false scriptFrom: local # 默认 pluginRootPath: live2dw/ # 插件在站点上的根目录(相对路径) pluginJsPath: lib/ # 脚本文件相对与插件根目录路径 pluginModelPath: assets/ # 模型文件相对与插件根目录路径 # scriptFrom: jsdelivr # jsdelivr CDN # scriptFrom: unpkg # unpkg CDN # scriptFrom: https://cdn.jsdelivr.net/npm/live2d-widget@3.x/lib/L2Dwidget.min.js # 你的自定义 url tagMode: false # 标签模式, 是否仅替换 live2d tag标签而非插入到所有页面中 debug: false # 调试, 是否在控制台输出日志 model: use: live2d-widget-model-wanko # npm-module package name # use: wanko # 博客根目录/live2d_models/ 下的目录名 # use: ./wives/wanko # 相对于博客根目录的路径 # use: https://cdn.jsdelivr.net/npm/live2d-widget-model-wanko@1.0.5/assets/wanko.model.json # 你的自定义 url 详细配置(本配置可以定义挂件位置、大小、缩放和手机端是否显示)​ live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-wanko display: position: right width: 150 height: 300 mobile: show: true react: opacity: 0.7 高级配置 用户高度自定义设置，小白玩家不必理会，老司机请随意，官方API地址：L2Dwidget | live2d-widget.js 模型模型的安装有两种方式： 1、使用 npm 下载的模型直接通过npm来安装，然后编辑配置文件中的model.use项，将其修改为模型的包名​ npm install live2d-widget-model-shizuku 所有模型列表如下： live2d-widget-model-chitose live2d-widget-model-epsilon2_1 live2d-widget-model-gf live2d-widget-model-haru/01 (use npm install –save live2d-widget-model-haru) live2d-widget-model-haru/02 (use npm install –save live2d-widget-model-haru) live2d-widget-model-haruto live2d-widget-model-hibiki live2d-widget-model-hijiki live2d-widget-model-izumi live2d-widget-model-koharu live2d-widget-model-miku live2d-widget-model-ni-j live2d-widget-model-nico live2d-widget-model-nietzsche live2d-widget-model-nipsilon live2d-widget-model-nito live2d-widget-model-shizuku live2d-widget-model-tororo live2d-widget-model-tsumiki live2d-widget-model-unitychan live2d-widget-model-wanko live2d-widget-model-z16 2、使用自己下载的模型方式一（推荐使用）： 在博客根目录下创建一个live2d_models文件夹 在此文件夹内新建一个子文件夹 将你的Live2D模型复制到这个子文件夹中，自有模型应当有一个.model.json文件 (例如 hijiki.model.json) 将子文件夹的名称配置到配置文件中的model.use项 目录结构如下 1234567891011121314151617181920212223242526live2d_models └─hijiki │ .gitignore │ package-lock.json │ package.json │ └─assets │ hijiki.model.json │ hijiki.pose.json │ ├─moc │ │ hijiki.moc │ │ │ └─hijiki.2048 │ texture_00.png │ └─mtn 00_idle.mtn 01.mtn 02.mtn 03.mtn 04.mtn 05.mtn 06.mtn 07.mtn 08.mtn 方式二： 可直接输入相对于博客根目录的自定义路径到model.use中,示例: ./wives/shizuku 问题以上教程都是整合网上Hexo的live2d插件安装教程而来的，网上的教程都是在官方主题或者NexT主题的基础上进行配置的，我的博客使用的是icarus主题，使用网上的教程进行配置时除了会出现上面提到的主题配置文件配置live2d插件无效的问题,还有一个就是浏览器的控制台报错。虽然这个报错不影响页面，作为完美主义者和有一点小强迫症的我，怎么能让我的小站出现报红，通过关键字排查，终于发现问题所在和解决方案。 在icarus主题配置文件`_config.yml的plugins.mathjax属性默认是true,将该属性值改为false,重新生成部署，完美！MathJax是前端支持数学公式的一个插件，为了让前端支持LaTex的数学公式，并且渲染好看的样式。关闭了这个插件不知道会影响到什么，知道的大大麻烦留言一下，谢谢！ 参考文章： Hexo 博客利用 live2d 插件放置一个萌萌哒看板娘 在Hexo博客上添加可爱的Live 2D模型","link":"/2019/07/10/Hexo-Icarus主题引入live2d插件和解决配置冲突/"},{"title":"Java的基本类型","text":"一、Java的基本类型主要分为整数型，浮点型，字符型，布尔型。 ​ 整数型：byte，short，int，long； ​ 浮点型：float，double ​ 布尔型：boolean ​ 字符型：char 二、基本类型的大小 ​ byte：8位，最大存储数据量是255，存放的数据范围是-128~127之间。 ​ short：16位，最大数据存储量是65536，数据范围是-32768~32767之间。 ​ int：32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。 ​ long：64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。 ​ float：32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。 ​ double：64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。 ​ boolean：值只可以为true或者false ，理论上只占据一个bit，但是实际是占据了一个byte ​ char：16位，存储Unicode码，用单引号赋值。 ​ 位（bit）代表一个1或者0，是计算机的基本单位。 简单类型 boolean byte char short Int long float double 二进制位数 1 8 16 16 32 64 32 64 封装器类 Boolean Byte Character Short Integer Long Float Double 三、整数型的阈值 ​ 在计算机中，整数型使用二进制方式表示：而每一个整数型的第一个二进制位都是作为符号位， 0=正 1=负。 ​ 所以 byte｛-2^7，2^7-1｝ ​ short｛-2^15,-2^15-1｝ ​ int｛-2^23,-2^23-1｝ ​ long｛-2^31,-2^31-1｝ 四、基本类型的存储 ​ 基本类型存储于内存的常量池中，而在1.8以后常量池也又堆中转化到了直接内存的方法区中。 五、基本类型的默认与创建 ​ 整数都默认为int类型，浮点数都默认为double类型 ​ 由于基本类型的创建：先去常量池中找是否存在该值，如果存在直接调取引用，如果不存在则先在常量池中创建该值，在调引用 ​ 所以，不可以创建一个空值给基本数据类型。","link":"/2019/12/26/Java的基本类型/"},{"title":"Win10设置右键以管理员方式打开cmd","text":"123456789101112131415161718Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\runas]\"ShowBasedOnVelocityId\"=dword:639bc8 [HKEY_CLASSES_ROOT\\Directory\\shell\\runas]@=\"在此处打开命令提示符\"\"Icon\"=\"cmd.exe\" [HKEY_CLASSES_ROOT\\Directory\\shell\\runas\\command]@=\"cmd.exe /s /k pushd \\\"%V\\\"\" [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\runas]@=\"在此处打开命令窗口\"\"Icon\"=\"cmd.exe\" [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\runas\\command]@=\"cmd.exe /s /k pushd \\\"%V\\\"\"","link":"/2019/11/26/Win10设置右键以管理员方式打开cmd/"},{"title":"git常用命令和故障","text":"问题1、git 出现 SSL certificate problem: unable to get local issuer certificategit config --global http.sslVerify false","link":"/2019/07/09/git常用命令和故障/"},{"title":"springboot的@Transactional造成业务死锁","text":"","link":"/2019/07/31/springboot的-Transactional造成业务死锁/"},{"title":"redis中主从、哨兵和集群三者的区别","text":"","link":"/2020/01/10/redis中主从、哨兵和集群三者的区别/"},{"title":"spring-boot运行jar命令提示没有主清单属性","text":"背景在开发项目的过程中，spring-boot项目打包成可执行jar，一直能正常运行，后来需要引入同事封装的一个权限框架，依赖了两个jar包，引入之后再使用mvn package将项目打包成可执行jar，运行时就会显示没有主清单属性 问题查看jar包中MANIFEST.MF文件，没有发现Main-Class等配置，从而导致spring-boot运行jar命令提示没有主清单属性 1234Manifest-Version: 1.0Built-By: KailACreated-By: Apache Maven 3.6.0Build-Jdk: 1.8.0_141 经过网上查阅资料不断排查，发现项目内除了springboot主工程main方法的类使用了@SpringBootApplication注解，新依赖的jar包里也有一个带有main方法的类并且都使用了@SpringBootApplication注解 情景再现如果工程内有两个带有main方法的类并且都使用@SpringBootApplication注解（或者另一种情形：有两个main方法并且所在类都没有使用@SpringBootApplication注解，但是如果有多个main方法，只有一个使用@SpringBootApplication注解并不会引发此问题），同时pom.xml的maven打包插件配置如下： 123456789101112&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 解决方法查看Springboot官方文档的8.1.2. Packaging Executable Jar and War Files关于maven打包插件的说明 当工程没有指定&lt;mainClass&gt;或者继承了spring-boot-starter-parent并且属性未配置时，插件会自动寻找签名是public static void main(String[] args)的方法，当存在两个main方法时，插件会无法识别哪一个main方法才是主函数 1、通用解决方法：&lt;configuration&gt;下配置mainClass，指定程序入口。 123456789101112131415161718&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt; &lt;configuration&gt; &lt;!-- 解决本地jar不能打入部署包的问题 --&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;!-- 指定程序入口 --&gt; &lt;mainClass&gt;app.Application&lt;/mainClass&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 配置打包后的MANIFEST.MF文件 123456789Manifest-Version: 1.0Built-By: KailAStart-Class: app.ApplicationSpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Spring-Boot-Version: 1.5.8.RELEASECreated-By: Apache Maven 3.6.0Build-Jdk: 1.8.0_141Main-Class: org.springframework.boot.loader.JarLauncher 2、解决方法二，此方法有一定的限制，只有在你的pom.xml继承自spring-boot-starter-parent可以直接在&lt;properties&gt;配置&lt;start-class&gt;,直接对应清单文件里的Start-Class 123&lt;properties&gt; &lt;start-class&gt;com.xx.webapps.api.main.WebappsApiBidMain&lt;/start-class&gt;&lt;/properties&gt; 参考文章： Spring Boot Maven Plugin打包异常及三种解决方法：Unable to find main class maven引入本地jar不能打入部署包的问题解决","link":"/2019/07/09/spring-boot运行jar命令提示没有主清单属性/"},{"title":"使用String.valueOf避免，toString的空指针陷阱","text":"","link":"/2019/07/19/使用String-valueOf避免，toString的空指针陷阱/"},{"title":"循环遍历CopyOnWriteArrayList的remove方法导致的程序逻辑错误","text":"在使用CopyOnWriteArrayList使用不同的遍历方式调用remove方法会有什么陷阱？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package app;import java.util.*;import java.util.concurrent.CopyOnWriteArrayList;public class JavaApplicationDemo { public static void main(String[] args) { List&lt;String&gt; ids = new ArrayList&lt;String&gt;(); ids.add(\"1\"); ids.add(\"2\"); ids.add(\"2\"); ids.add(\"3\"); ids.add(\"4\"); ids.add(\"5\"); System.out.println(\"原始数组\"); for (String id : ids) { System.out.println(id); } CopyOnWriteArrayList&lt;String&gt; idsCopy1 = new CopyOnWriteArrayList&lt;String&gt;(ids); CopyOnWriteArrayList&lt;String&gt; idsCopy2 = new CopyOnWriteArrayList&lt;String&gt;(ids); CopyOnWriteArrayList&lt;String&gt; idsCopy3 = new CopyOnWriteArrayList&lt;String&gt;(ids); /************************* 使用简单for循环 *******************************/ System.out.println(\"使用for\"); for (int i = 0; i &lt; idsCopy1.size(); i++) { if (idsCopy1.get(i).equals(\"2\")) { idsCopy1.remove(idsCopy1.get(i)); System.out.println(\"The length of ids is \" + idsCopy1.size()); } } for (String id : idsCopy1) { System.out.println(id); } /************************* 使用foreach循环 *******************************/ System.out.println(\"使用foreach\"); for (String id : idsCopy2) { if (id.equals(\"2\")) { idsCopy2.remove(id); System.out.println(\"The length of ids is \" + idsCopy2.size()); } } for (String id : idsCopy2) { System.out.println(id); } /************************* 使用迭代器遍历 *******************************/ System.out.println(\"使用迭代器遍历\"); Iterator&lt;String&gt; listIt = idsCopy3.iterator(); while (listIt.hasNext()) { Object obj = listIt.next(); if (obj.equals(\"2\")) { idsCopy3.remove(obj); System.out.println(\"The length of ids is \" + idsCopy3.size()); } } for (String id : idsCopy3) { System.out.println(id); } /* * Exception in thread \"main\" java.util.ConcurrentModificationException at * java.util.ArrayList$Itr.checkForComodification(Unknown Source) at * java.util.ArrayList$Itr.next(Unknown Source) at * app.JavaApplicationDemo.main(JavaApplicationDemo.java:14) */ }} 原始数组 1 2 2 3 4 5 使用for The length of ids is 5 1 2 3 4 5 使用foreach The length of ids is 5 The length of ids is 4 1 3 4 5 使用迭代器遍历 The length of ids is 5 The length of ids is 4 1 3 4 5","link":"/2019/08/07/循环遍历CopyOnWriteArrayList的remove方法导致的程序逻辑错误/"},{"title":"Java位运算符示例代码","text":"一、位运算符1、位与运算符（&amp;） 运算规则：两个整数都转为二进制，然后从高位开始比较，如果两个数同一位都为1则为1，否则为0。 比如：9&amp;8 9转换成二进制就是1001，8转换成二进制就是1000。 1001 1000 -------- 1000从高位开始比较得到，得到1000，即8。 2、位或运算符（|） 运算规则：两个整数都转为二进制，然后从高位开始比较，两个数同一位只要有一个为1则为1，否则就为0。 比如：9|12 9转换成二进制就是1001，12转换成二进制就是1100。 1001 1100 -------- 1101 从高位开始比较得到，得到1101，即13。 3、位非运算符（~） 运算规则：操作数转为二进制，如果位为0，结果是1，如果位为1，结果是0. 比如：~37在Java中，所有数据的表示方法都是以补码的形式表示，如果没有特殊说明，Java中的数据类型默认是int,int 是4个字节（byte），一个字节8位（bit），就是32字节，32bit. 8转为二进制是100101。 补码后为： 00000000 00000000 00000000 00100101 取反为： 11111111 11111111 11111111 11011010 因为高位是1，所以原码为负数，负数的补码是其绝对值的原码取反，末尾再加1。 因此，我们可将这个二进制数的补码进行还原： 首先，末尾减1得反码： 11111111 11111111 11111111 11011001 其次，将各位取反得原码：00000000 00000000 00000000 00100110，此时二进制转原码为38。所以~37 = -38。 4、位异或运算（^） 运算规则是：两个整数转为二进制，然后从高位开始比较，如果同一位相同则为0，不相同则为1。 比如：8^11 8转为二进制是1000，11转为二进制是1011. 1000 1011 -------- 0011 从高位开始比较得到的是：0011，即3。 5、移位运算符（&lt;&lt;、&gt;&gt;、&gt;&gt;&gt;） 移位运算符有双目移位运算符：&lt;&lt;（左移）和&gt;&gt;（右移）。 移位运算符组成的表达式也属于算术表达式，其值为算术值。 左移运算是将一个二进制位的操作数按指定移动的位数向左移位，移出位被丢弃，右边的空位一律补0。 右移运算是将一个二进制位的操作数按指定移动的位数向右移动，移出位被丢弃，左边移出的空位或者一律补0，或者补符号位，这由不同的机器而定。在使用补码作为机器数的机器中，正数的符号位为0，负数的符号位为1, 说白了，就是把要移动的数转换成2进制，右移几位就去掉右边的几位数，左移几位就在右边加几个0。 例如： 14转成二进制变成1110，右移2位就是去掉右边的10，变成11，11转成十进制就是3；左移2位就是111000，转成十进制就是56。0000 1111(15)右移2位的结果是0000 0011(3)，0001 1010(18)右移位3位的结果也是0000 0011(3)。 &gt;&gt;&gt;表示无符号右移，也叫逻辑右移，即若该数为正，则高位补0，而若该数为负数，则右移后高位同样补0。 例如：20 &gt;&gt; 2 20的二进制为 0001 0100，右移2位后为 0000 0101，即5; -20 &gt;&gt; 2; -20的二进制为 1110 1011，右移2位，此时高位补0，即 0011 1010，即-5; 左移没有&lt;&lt;&lt;运算符！ 二、代码1、代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class Operator { public static void main(String args[]) { System.out.println(9+\"&amp;\"+8+\"十进制的值：\"+(9&amp;8)+\"，二进制的值：\"+Integer.toBinaryString(9&amp;8)); System.out.println(9+\"|\"+12+\"十进制的值：\"+(9|12)+\"，二进制的值：\"+Integer.toBinaryString(9|12)); System.out.println(\"~\"+27+\"十进制的值：\"+(~37)+\"，二进制的值：\"+Integer.toBinaryString(~37)); System.out.println(8+\"^\"+11+\"十进制的值：\"+(8^11)+\"，二进制的值：\"+Integer.toBinaryString(8^11)); System.out.println(\"----------------\"); int m = 8; int mr1 = m&gt;&gt;1; int mr2 = m&gt;&gt;2; int mr3 = m&gt;&gt;3; int mrr1 = m&gt;&gt;&gt;1; int mrr2 = m&gt;&gt;&gt;2; int mrr3 = m&gt;&gt;&gt;3; int ml1 = m&lt;&lt;1; int ml2 = m&lt;&lt;2; int ml3 = m&lt;&lt;3; System.out.println(\"十进制的值：\"+m+\"，二进制的值：\"+Integer.toBinaryString(m)); System.out.println(\"----------------\"); System.out.println(\"&gt;&gt;右移一位，十进制的值:\"+mr1+\"，二进制的值：\"+Integer.toBinaryString(mr1)); System.out.println(\"&gt;&gt;右移二位，十进制的值:\"+mr2+\"，二进制的值：\"+Integer.toBinaryString(mr2)); System.out.println(\"&gt;&gt;右移三位，十进制的值:\"+mr3+\"，二进制的值：\"+Integer.toBinaryString(mr3)); System.out.println(\"----------------\"); System.out.println(\"&gt;&gt;&gt;右移一位，十进制的值:\"+mrr1+\"，二进制的值：\"+Integer.toBinaryString(mrr1)); System.out.println(\"&gt;&gt;&gt;右移二位，十进制的值:\"+mrr2+\"，二进制的值：\"+Integer.toBinaryString(mrr2)); System.out.println(\"&gt;&gt;&gt;右移三位，十进制的值:\"+mrr3+\"，二进制的值：\"+Integer.toBinaryString(mrr3)); System.out.println(\"----------------\"); System.out.println(\"&lt;&lt;左移一位，十进制的值:\"+ml1+\"，二进制的值：\"+Integer.toBinaryString(ml1)); System.out.println(\"&lt;&lt;左移二位，十进制的值:\"+ml2+\"，二进制的值：\"+Integer.toBinaryString(ml2)); System.out.println(\"&lt;&lt;左移三位，十进制的值:\"+ml3+\"，二进制的值：\"+Integer.toBinaryString(ml3)); System.out.println(\"----------------\"); int n = -8; int nr1 = n&gt;&gt;1; int nr2 = n&gt;&gt;2; int nr3 = n&gt;&gt;3; int nrr1 = n&gt;&gt;&gt;1; int nrr2 = n&gt;&gt;&gt;2; int nrr3 = n&gt;&gt;&gt;3; int nl1 = n&lt;&lt;1; int nl2 = n&lt;&lt;2; int nl3 = n&lt;&lt;3; System.out.println(\"十进制的值：\"+n+\"，二进制的值：\"+Integer.toBinaryString(n)); System.out.println(\"----------------\"); System.out.println(\"&gt;&gt;右移一位，十进制的值:\"+nr1+\"，二进制的值：\"+Integer.toBinaryString(mr1)); System.out.println(\"&gt;&gt;右移二位，十进制的值:\"+nr2+\"，二进制的值：\"+Integer.toBinaryString(mr2)); System.out.println(\"&gt;&gt;右移三位，十进制的值:\"+nr3+\"，二进制的值：\"+Integer.toBinaryString(mr3)); System.out.println(\"----------------\"); System.out.println(\"&gt;&gt;&gt;右移一位，十进制的值:\"+nrr1+\"，二进制的值：\"+Integer.toBinaryString(nrr1)); System.out.println(\"&gt;&gt;&gt;右移二位，十进制的值:\"+nrr2+\"，二进制的值：\"+Integer.toBinaryString(nrr2)); System.out.println(\"&gt;&gt;&gt;右移三位，十进制的值:\"+nrr3+\"，二进制的值：\"+Integer.toBinaryString(nrr3)); System.out.println(\"----------------\"); System.out.println(\"&lt;&lt;左移一位，十进制的值:\"+nl1+\"，二进制的值：\"+Integer.toBinaryString(nl1)); System.out.println(\"&lt;&lt;左移二位，十进制的值:\"+nl2+\"，二进制的值：\"+Integer.toBinaryString(nl2)); System.out.println(\"&lt;&lt;左移三位，十进制的值:\"+nl3+\"，二进制的值：\"+Integer.toBinaryString(nl3)); } } 2、输出结果：9&amp;8十进制的值：8，二进制的值：1000 9|12十进制的值：13，二进制的值：1101 ~27十进制的值：-38，二进制的值：11111111111111111111111111011010 8^11十进制的值：3，二进制的值：11 ---------------- 十进制的值：8，二进制的值：1000 ---------------- &gt;&gt;右移一位，十进制的值:4，二进制的值：100 &gt;&gt;右移二位，十进制的值:2，二进制的值：10 &gt;&gt;右移三位，十进制的值:1，二进制的值：1 ---------------- &gt;&gt;&gt;右移一位，十进制的值:4，二进制的值：100 &gt;&gt;&gt;右移二位，十进制的值:2，二进制的值：10 &gt;&gt;&gt;右移三位，十进制的值:1，二进制的值：1 ---------------- &lt;&lt;左移一位，十进制的值:16，二进制的值：10000 &lt;&lt;左移二位，十进制的值:32，二进制的值：100000 &lt;&lt;左移三位，十进制的值:64，二进制的值：1000000 ---------------- 十进制的值：-8，二进制的值：11111111111111111111111111111000 ---------------- &gt;&gt;右移一位，十进制的值:-4，二进制的值：100 &gt;&gt;右移二位，十进制的值:-2，二进制的值：10 &gt;&gt;右移三位，十进制的值:-1，二进制的值：1 ---------------- &gt;&gt;&gt;右移一位，十进制的值:2147483644，二进制的值：1111111111111111111111111111100 &gt;&gt;&gt;右移二位，十进制的值:1073741822，二进制的值：111111111111111111111111111110 &gt;&gt;&gt;右移三位，十进制的值:536870911，二进制的值：11111111111111111111111111111 ---------------- &lt;&lt;左移一位，十进制的值:-16，二进制的值：11111111111111111111111111110000 &lt;&lt;左移二位，十进制的值:-32，二进制的值：11111111111111111111111111100000 &lt;&lt;左移三位，十进制的值:-64，二进制的值：11111111111111111111111111000000","link":"/2019/12/07/Java位运算符示例代码/"},{"title":"从Windows过度到Mac必备快捷键对照表","text":"windows和mac快捷键 Mac 键盘符号说明 ⌘ == Command ⇧ == Shift ⇪ == Caps Lock ⌥ == Option ⌃ == Control ↩ == Return/Enter ⌫ == Delete ⌦ == 向前删除键（Fn+Delete） ↑ == 上箭头 ↓ == 下箭头 ← == 左箭头 → == 右箭头 ⇞ == Page Up（Fn+↑） ⇟ == Page Down（Fn+↓） Home == Fn + ← End == Fn + → ⇥ == 右制表符（Tab键） ⇤ == 左制表符（Shift+Tab） ⎋ == Escape (Esc) ⏏ == 电源开关键 Ctrl Win 快捷键 Mac 快捷键 介绍 Ctrl + F Command + F 在当前文件进行文本查找 Ctrl + R Command + R 在当前文件进行文本替换 Ctrl + Z Command + Z 撤销 Ctrl + Y Command + Delete 删除光标所在行 或 删除选中的行 Ctrl + D Command + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 Ctrl + W Option + 方向键上 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 Ctrl + E Command + E 显示最近打开的文件记录列表 Ctrl + N Command + O 根据输入的 类名 查找类文件 Ctrl + J Command + J 插入自定义动态代码模板 Ctrl + P Command + P 方法参数提示显示 Ctrl + U Command + U 前往当前光标所在的方法的父类的方法 / 接口定义 Ctrl + B Command + B 进入光标所在的方法/变量的接口或是定义处，等效于 Ctrl + 左键单击 Ctrl + / Command + / 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 Ctrl + F1 Command + F1 在光标所在的错误代码处显示错误信息 Ctrl + F11 Option + F3 选中文件 / 文件夹，使用助记符设定 / 取消书签 Ctrl + F12 Command + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Ctrl + Space Control + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号 Ctrl + Delete Option + Fn+ Delete 删除光标后面的单词或是中文句 Ctrl + BackSpace Option + Delete 删除光标前面的单词或是中文句 Ctrl + 1,2,3...9 Control + 1,2,3...9 定位到对应数值的书签位置 Ctrl + 加号 Command + 加号 展开代码 Ctrl + 减号 Command + 减号 折叠代码 Ctrl + 左键单击 Control + 左键单击 在打开的文件标题上，弹出该文件路径 Ctrl + 左方向键 Option + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 Ctrl + 右方向键 Option + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 Ctrl + 前方向键 预设中没有该快捷键 等效于鼠标滚轮向前效果 Ctrl + 后方向键 预设中没有该快捷键 等效于鼠标滚轮向后效果 Alt Win 快捷键 Mac 快捷键 介绍 Alt + ` Control + V 显示版本控制常用操作菜单弹出层 Alt + F1 Option + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 Alt + F7 Option + F7 查询所选对象/变量被引用 Alt + Enter Option + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 Alt + Insert Command + N 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 Alt + 左方向键 Control + 左方向键 切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 Alt + 右方向键 Control + 右方向键 切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 Alt + 前方向键 Control + 前方向键 当前光标跳转到当前文件的前一个方法名位置 Alt + 后方向键 Control + 后方向键 当前光标跳转到当前文件的后一个方法名位置 Alt + 1,2,3...9 Command + 1,2,3...9 显示对应数值的选项卡，其中 1 是 Project 用得最多 Shift Win 快捷键 Mac 快捷键 介绍 Shift + F11 Command + F3 弹出书签显示层 Shift + Tab Shift + Tab 取消缩进 Shift + Enter Shift + Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 Shift + 左键单击 Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 Ctrl + Alt Win 快捷键 Mac 快捷键 介绍 Ctrl + Alt + L Command + Option + L 格式化代码，可以对当前文件和整个包目录使用 Ctrl + Alt + O Control + Option + O 优化导入的类，可以对当前文件和整个包目录使用 Ctrl + Alt + T Command + Option + T 对选中的代码弹出环绕选项弹出层 Ctrl + Alt + S Command + 逗号 打开 IntelliJ IDEA 系统设置 Ctrl + Alt + Enter Command + Option + Enter 光标所在行上空出一行，光标定位到新行 Ctrl + Alt + 左方向键 Command + Option + 左方向键 退回到上一个操作的地方 Ctrl + Alt + 右方向键 Command + Option + 右方向键 前进到上一个操作的地方 Ctrl + Shift Win 快捷键 Mac 快捷键 介绍 Ctrl + Shift + F Command + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 Ctrl + Shift + R Command + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 Ctrl + Shift + J Control + Shift + J 自动将下一行合并到当前行末尾 Ctrl + Shift + Z Command + Shift + Z 取消撤销 Ctrl + Shift + W Option + 方向键下 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 Ctrl + Shift + N Command + Shift + O 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 Ctrl + Shift + U Command + Shift + U 对选中的代码进行大 / 小写轮流转换 Ctrl + Shift + T Command + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 Ctrl + Shift + C Command + Shift + C 复制当前文件磁盘路径到剪贴板 Ctrl + Shift + B Control + Shift + B 跳转到类型声明处 Ctrl + Shift + / Command + Option + / 代码块注释 Ctrl + Shift + [ Command + Shift + [ 选中从光标所在位置到它的顶部中括号位置 Ctrl + Shift + ] Command + Shift + ] 选中从光标所在位置到它的底部中括号位置 Ctrl + Shift + 加号 Command + Shift + 加号 展开所有代码 Ctrl + Shift + 减号 Command + Shift + 减号 折叠所有代码 Ctrl + Shift + F7 Command + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失 Ctrl + Shift + F12 Command + Shift + F12 编辑器最大化 Ctrl + Shift + Enter Command + Shift + Enter 自动结束代码，行末自动添加分号 Ctrl + Shift + Backspace Ctrl + Shift + Backspace 退回到上次修改的地方 Ctrl + Shift + 1,2,3...9 Control + Shift + 1,2,3...9 快速添加指定数值的书签 Ctrl + Shift + 左键单击 Command + Shift + 左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 Ctrl + Shift + 左方向键 Option + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 右方向键 Option + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 前方向键 Command + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 Ctrl + Shift + 后方向键 Command + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 Alt + Shift Win 快捷键 Mac 快捷键 介绍 Alt + Shift + N Option + Shift + B 选择 / 添加 task Alt + Shift + 左键双击 Option + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 Alt + Shift + 前方向键 Option + Shift + 前方向键 移动光标所在行向上移动 Alt + Shift + 后方向键 Option + Shift + 后方向键 移动光标所在行向下移动 Ctrl + Shift + Alt Win 快捷键 Mac 快捷键 介绍 Ctrl + Shift + Alt + V Command + Shift + Option + V 无格式黏贴 Ctrl + Shift + Alt + S Command + ; 打开当前项目设置 其他 Win 快捷键 Mac 快捷键 介绍 F2 F2 跳转到下一个高亮错误 或 警告位置 F4 F4 编辑源 F11 F3 添加书签 F12 F12 回到前一个工具窗口 Tab Tab 缩进 ESC ESC 从工具窗口进入代码文件窗口 本文转发自《尚硅谷Java开发利器：IntelliJ IDEA的安装、配置与使用》教程中的文档","link":"/2019/09/25/[转发]从Windows过度到Mac必备快捷键对照表/"},{"title":"什么是Redis缓存穿透、缓存雪崩和缓存击穿","text":"一、缓存处理流程前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。 二、缓存穿透缓存穿透，是指查询一个数据库一定不存在的数据，大量请求穿透redis,直接对数据库造成压力，甚至压垮数据库。 正常的使用缓存流程大致是，数据查询先进行缓存查询，如果key不存在或者key已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存。 12345678910111213public Goods searchArticleById(Long goodsId){ Object object = redisTemplate.opsForValue().get(String.valueOf(goodsId)); if(object != null){//缓存查询命中 return (Goods) object; } //缓存查询没有命中，开始数据库查询 Goods goods = goodsMapper.selectByPrimaryKey(goodsId); System.out.println(\"====主键ID：\"+goodsId+\"，进行了数据库查询====\"); if(goods != null){ redisTemplate.opsForValue.set(String.valueOf(goodsId),goods,60,TimeUnit.MINUTES); } return goods;} 代码流程 1、参数传入对象主键ID 2、根据key从缓存中获取对象 3、如果对象不为空，直接返回 3、如果对象为空，进行数据库查询 5、如果从数据库查询出的对象不为空，则放入缓存（设定过期时间） 想象一下这个情况，如果传入的参数为-1，会是怎么样？这个-1，就是一定不存在的对象。就会每次都去查询数据库，而每次查询都是空，每次又都不会进行缓存。假如有恶意攻击，就可以利用这个漏洞，对数据库造成压力，甚至压垮数据库。即便是采用UUID，也是很容易找到一个不存在的KEY，进行攻击。 解决方案： 1、接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截； 2、采用布隆过滤器，使用一个足够大的bitmap，用于存储可能访问的key，不存在的key直接被过滤； 3、从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。 123456789101112131415public Goods searchArticleById(Long goodsId){ Object object = redisTemplate.opsForValue().get(String.valueOf(goodsId)); if(object != null){//缓存查询命中 return (Goods) object; } //缓存查询没有命中，开始数据库查询 Goods goods = goodsMapper.selectByPrimaryKey(goodsId); System.out.println(\"====主键ID：\"+goodsId+\"，进行了数据库查询====\"); if(goods != null){ redisTemplate.opsForValue.set(String.valueOf(goodsId),goods,60,TimeUnit.MINUTES); }else{ redisTemplate.opsForValue.set(String.valueOf(goodsId),null,30,TimeUnit.SECONDS); } return goods;} 三、缓存击穿缓存击穿，是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。 解决方案： 1、不设置缓存时间（设置数据永远不过期），由后台创建定时任务去维护这部分缓存数据。这种方法请求时直接从缓存中获取数据，无需再判断是否从数据库中获取，定时任务也可在请求较少的时间段分批更新缓存数据。当然代码量、代码复杂度增大，分批更新代表需要多个定时任务去维护缓存数据，同时更新有可能会造成缓存雪崩的情况； 2、使用同步锁 synchronized 关键字，修饰在获取缓存的方法里面，保证在多用户同时请求条件下，只有第一个进入的线程去判断是否要查询数据库并存入缓存，其他线程只需在第一个线程结束后，从缓存中读取数据即可，无需再查询数据库。（本方法只适用于单节点站点） 12345678910111213141516171819202122public Goods searchArticleById(Long goodsId){ Goods goods = (Goods)redisTemplate.opsForValue().get(String.valueOf(goodsId)); if(goods == null){//缓存查询命中 //第一个线程进入获取缓存中的数据，其他线程等待 synchronized(this){ goods = (Goods)redisTemplate.opsForValue().get(String.valueOf(goodsId)); if(goods == null){ //缓存查询没有命中，开始数据库查询 goods = goodsMapper.selectByPrimaryKey(goodsId); System.out.println(\"====主键ID：\"+goodsId+\"，进行了数据库查询====\"); if(goods == null){ //数据库中没有查询到数据，设置空值，缓存有效时间为30秒 redisTemplate.opsForValue.set(String.valueOf(goodsId),null,30,TimeUnit.SECONDS); } }else{ //可用数据在redis中存储60分钟 redisTemplate.opsForValue.set(String.valueOf(goodsId),goods,60,TimeUnit.MINUTES); } } } return goods;} 3、使用互斥锁加锁获取缓存。也就是当获取的value值为空时（这里的空表示缓存过期），先加锁，然后从数据库加载并放入缓存，最后释放锁。如果其他线程获取锁失败，则睡眠一段时间后重试。下面使用Redis的setnx来实现分布式锁，如下所示： 1234567891011121314151617181920212223242526272829public Goods searchArticleById(Long goodsId){ Goods goods = (Goods)redisTemplate.opsForValue().get(String.valueOf(goodsId)); if(goods == null){//缓存查询命中 //设置3分钟过期时间，避免互斥锁死锁 String key_mutex = String.valueOf(goodsId))+\"_mutex\"; if (redisTemplate.opsForValue().setIfAbsent(key_mutex,\"1\",3 * 60, TimeUnit.SECONDS)) { goods = goodsMapper.selectByPrimaryKey(goodsId); System.out.println(\"====主键ID：\"+goodsId+\"，进行了数据库查询====\"); if(goods == null){ //缓存查询没有命中，开始数据库查询 goods = goodsMapper.selectByPrimaryKey(goodsId); System.out.println(\"====主键ID：\"+goodsId+\"，进行了数据库查询====\"); if(goods == null){ //数据库中没有查询到数据，设置空值，缓存有效时间为30秒 redisTemplate.opsForValue.set(String.valueOf(goodsId),null,30,TimeUnit.SECONDS); } }else{ //可用数据在redis中存储60分钟 redisTemplate.opsForValue.set(String.valueOf(goodsId),goods,60,TimeUnit.MINUTES); } redisTemplate.opsForValue().getOperations().delete(key_mutex); } else { //其他线程休息50毫秒后重试 Thread.sleep(50); return searchArticleById(Long goodsId); } } return goods;} 四、缓存雪崩缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至宕机或断网。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。其实集中过期，倒不是非常致命，比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网。因为自然形成的缓存雪崩，一定是在某个时间段集中创建缓存，那么那个时候数据库能顶住压力，这个时候，数据库也是可以顶住压力的。无非就是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。 12345678910111213141516171819Goods goods = goodsMapper.selectByPrimaryKey(goodsId);if(goods ！= null){//数据库查询不为空 if(goods.getGoodsCategory().equals(\"女装\")){ //热门商品类目 Random r = new Random(); int time =3600 +r.nextint(36000);//随机 redisTemplate.opsForValue.set(String.valueOf(goodsId),goods,time,TimeUnit.MINUTES); } if(goods.getGoodsCategory().equals(\"图书\")){ //冷门商品类目 Random r = new Random(); int time =600 +r.nextint(600);//随机 redisTemplate.opsForValue.set(String.valueOf(goodsId),goods,time,TimeUnit.MINUTES); }}else{ //空对象 redisTemplate.opsForValue.set(String.valueOf(goodsId),null,30,TimeUnit.SECONDS);} return goods; 解决方案： 1、缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生； 2、如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中； 3、设置热点数据永远不过期。","link":"/2020/01/13/什么是Redis缓存穿透、缓存雪崩和缓存击穿/"},{"title":"BloomFilter算法","text":"在开发或者面试过程中，遇到过海量数据需要查重，缓存穿透怎么避免等等这样的问题有什么方案可以提供？这时就要想到我们的BloomFilter。 一、专业术语开始了解Bloom Filter算法，先介绍一下False Positive和False Negative的概念。False Positive中文可以理解为“假阳性”，形象的一点说就是“误报”，后面将会说道Bloom Filter存在误报的情况，现实生活中也有误报，比如说去体检的时候，医生告诉你XXX检测是阳性，而实际上是阴性，也就是说误报了，是假阳性，杀毒软件误报也是同样的概念。False Negative，中文可以理解为“假阴性”，形象的一点说是“漏报”。医生告诉你XXX检测为阴性，实际上你是阳性，你是有病的（Sorry, it’s just a joke），那就是漏报了。同样杀毒软件也存在漏报的情况。 二、简介Bloom Filter的中文翻译叫做布隆过滤器，是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 Bloom Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。 三、应用场景在正式介绍Bloom Filter算法之前，先来看看什么时候需要用到Bloom Filter算法。 1.HTTP缓存服务器、Web爬虫等主要工作是判断一条URL是否在现有的URL集合之中（可以认为这里的数据量级上亿）。对于HTTP缓存服务器，当本地局域网中的PC发起一条HTTP请求时，缓存服务器会先查看一下这个URL是否已经存在于缓存之中，如果存在的话就没有必要去原始的服务器拉取数据了（为了简单起见，我们假设数据没有发生变化），这样既能节省流量，还能加快访问速度，以提高用户体验。对于Web爬虫，要判断当前正在处理的网页是否已经处理过了，同样需要当前URL是否存在于已经处理过的URL列表之中。 2.垃圾邮件过滤假设邮件服务器通过发送方的邮件域或者IP地址对垃圾邮件进行过滤，那么就需要判断当前的邮件域或者IP地址是否处于黑名单之中。如果邮件服务器的通信邮件数量非常大（也可以认为数据量级上亿），那么也可以使用Bloom Filter算法。 四、Bloom Filter原理1.集合表示和元素查询初始状态 初始状态下，Bloom Filter是一个m位的位数组，且数组的每一位被0所填充。 插入元素 我们需要定义k个相互独立的哈希函数（Hash Function*），分别将集合中的每个元素映射到{1,…,m}的范围中。对任意一个元素x，第i个哈希函数映射的位置hi(x)就会被置为1（1≤i≤k）。那么对于一个确定的输入，我们会得到k个索引。我们把位数组中这k个位置全部置1（不管其中的位之前是0还是1），注意，如果一个位置多次被置为1，那么只有第一次会起作用，后面几次将没有任何效果。在下图中，k=3*，且有两个哈希函数选中同一个位置（从左边数第五位）。 查询元素 在判断y是否属于这个集合时，我们对y应用k次哈希函数，如果所有hi(y)的位置都是1（1≤i≤k），那么我们就认为y是集合中的元素，否则就认为y不是集合中的元素。下图中y1就不是集合中的元素。y2或者属于这个集合，或者刚好是一个false positive。 输入元素经过k个hash函数的映射会得到k个索引，如果位数组中这k个索引任意一处是0，那么就说明这个元素不在集合之中；如果元素处于集合之中，那么当插入元素的时候这k个位都是1。但如果这k个索引处的位都是1，被查询的元素就一定在集合之中吗？答案是不一定，也就是说出现了False Positive的情况（但Bloom Filter不会出现False Negative的情况） 插入和查询对比 在上图中，当插入x、y、z这三个元素之后，再来查询w，会发现w不在集合之中，而如果w经过三个hash函数计算得出的结果所得索引处的位全是1，那么Bloom Filter就会告诉你，w在集合之中，实际上这里是误报，w并不在集合之中。 2.False Positive RateBloom Filter的误报率到底有多大？下面在数学上进行一番推敲。假设HASH函数输出的索引值落在m位的数组上的每一位上都是等可能的。那么，对于一个给定的HASH函数，在进行某一个运算的时候，一个特定的位没有被设置为1的概率是 那么，对于所有的k个HASH函数，都没有把这个位设置为1的概率是 如果我们已经插入了n个元素，那么对于一个给定的位，这个位仍然是0的概率是 那么，如果插入n个元素之后，这个位是1的概率是 如果对一个特定的元素存在误报，那么这个元素的经过HASH函数所得到的k个索引全部都是1，概率也就是 根据常数e的定义，可以近似的表示为： 3.关于误报有时候误报对实际操作并不会带来太大的影响，比如对于HTTP缓存服务器，如果一条URL被误以为存在与缓存服务器之中，那么当取数据的时候自然会无法取到，最终还是要从原始服务器当中获取，之后再把记录插入缓存服务器，几乎没有什么不可以接受的。对于安全软件，有着“另可错报，不可误报”的说法，如果你把一个正常软件误判为病毒，对使用者来说不会有什么影响（如果用户相信是病毒，那么就是删除这个文件罢了，如果用户执意要执行，那么后果也只能由用户来承担）；如果你把一个病毒漏判了，那么对用户造成的后果是不可设想的……更有甚者，误报在某种程度上能让部分用户觉得你很专业…… 4.最优的哈希函数个数既然Bloom Filter要靠多个哈希函数将集合映射到位数组中，那么应该选择几个哈希函数才能使元素查询时的错误率降到最低呢？这里有两个互斥的理由：如果哈希函数的个数多，那么在对一个不属于集合的元素进行查询时得到0的概率就大；但另一方面，如果哈希函数的个数少，那么位数组中的0就多。为了得到最优的哈希函数个数，我们需要根据上一小节中的错误率公式进行计算。 先用p和f进行计算。注意到f = exp(k ln(1 − e−kn/m))，我们令g = k ln(1 − e−kn/m)，只要让g取到最小，f自然也取到最小。由于p = e-kn/m，我们可以将g写成 根据对称性法则可以很容易看出当p = 1/2，也就是k = ln2· (m/n)时，g取得最小值。在这种情况下，最小错误率f等于(1/2)k ≈ (0.6185)m/n。另外，注意到p是位数组中某一位仍是0的概率，所以p = 1/2对应着位数组中0和1各一半。换句话说，要想保持错误率低，最好让位数组有一半还空着。 需要强调的一点是，p = 1/2时错误率最小这个结果并不依赖于近似值p和f。同样对于f’ = exp(k ln(1 − (1 − 1/m)kn))，g’ = k ln(1 − (1 − 1/m)kn)，p’ = (1 − 1/m)kn，我们可以将g’写成 同样根据对称性法则可以得到当p’ = 1/2时，g’取得最小值。 5.位数组的大小下面我们来看看，在不超过一定错误率的情况下，Bloom Filter至少需要多少位才能表示全集中任意n个元素的集合。假设全集中共有u个元素，允许的最大错误率为є，下面我们来求位数组的位数m。 假设X为全集中任取n个元素的集合，F(X)是表示X的位数组。那么对于集合X中任意一个元素x，在s = F(X)中查询x都能得到肯定的结果，即s能够接受x。显然，由于Bloom Filter引入了错误，s能够接受的不仅仅是X中的元素，它还能够є (u - n)个false positive。因此，对于一个确定的位数组来说，它能够接受总共n + є (u - n)个元素。在n + є (u - n)个元素中，s真正表示的只有其中n个，所以一个确定的位数组可以表示 个集合。m位的位数组共有2m个不同的组合，进而可以推出，m位的位数组可以表示 个集合。全集中n个元素的集合总共有 个，因此要让m位的位数组能够表示所有n个元素的集合，必须有 即： 上式中的近似前提是n和єu相比很小，这也是实际情况中常常发生的。根据上式，我们得出结论：在错误率不大于є的情况下，m至少要等于n log2(1/є)才能表示任意n个元素的集合。 上一小节中我们曾算出当k = ln2· (m/n)时错误率f最小，这时f = (1/2)k = (1/2)mln2 / n。现在令f≤є，可以推出 这个结果比前面我们算得的下界n log2(1/є)大了log2 e ≈ 1.44倍。这说明在哈希函数的个数取到最优时，要让错误率不超过є，m至少需要取到最小值的1.44倍。 哈希函数个数k、位数组大小m、加入的字符串数量n的关系可以参考Bloom Filters - the math Bloom Filters - the math 6.总结在计算机科学中，我们常常会碰到时间换空间或者空间换时间的情况，即为了达到某一个方面的最优而牺牲另一个方面。Bloom Filter在时间空间这两个因素之外又引入了另一个因素：错误率。在使用Bloom Filter判断一个元素是否属于某个集合时，会有一定的错误率。也就是说，有可能把不属于这个集合的元素误认为属于这个集合（False Positive），但不会把属于这个集合的元素误认为不属于这个集合（False Negative）。在增加了错误率这个因素之后，Bloom Filter通过允许少量的错误来节省大量的存储空间。 自从Burton Bloom在70年代提出Bloom Filter之后，Bloom Filter就被广泛用于拼写检查和数据库系统中。近一二十年，伴随着网络的普及和发展，Bloom Filter在网络领域获得了新生，各种Bloom Filter变种和新的应用不断出现。可以预见，随着网络应用的不断深入，新的变种和应用将会继续出现，Bloom Filter必将获得更大的发展。 五、Counting Bloom Filter从前面对Bloom Filter的介绍可以看出，标准的Bloom Filter是一种很简单的数据结构，它只支持插入和查找两种操作。在所要表达的集合是静态集合的时候，标准Bloom Filter可以很好地工作，但是如果要表达的集合经常变动，标准Bloom Filter的弊端就显现出来了，因为它不支持删除操作。 Counting Bloom Filter的出现解决了这个问题，它将标准Bloom Filter位数组的每一位扩展为一个小的计数器（Counter），在插入元素时给对应的k（k为哈希函数个数）个Counter的值分别加1，删除元素时给对应的k个Counter的值分别减1。Counting Bloom Filter通过多占用几倍的存储空间的代价，给Bloom Filter增加了删除操作。下一个问题自然就是，到底要多占用几倍呢？ 我们先计算第i个Counter被增加j次的概率，其中n为集合元素个数，k为哈希函数个数，m为Counter个数（对应着原来位数组的大小）： 上面等式右端的表达式中，前一部分表示从nk次哈希中选择j次，中间部分表示j次哈希都选中了第i个Counter，后一部分表示其它nk – j次哈希都没有选中第i个Counter。因此，第i个Counter的值大于j的概率可以限定为： 上式第二步缩放中应用了估计阶乘的斯特林公式： 在Bloom Filter概念和原理一文中，我们提到过k的最优值为(ln2)m/n，现在我们限制k ≤ (ln2)m/n，就可以得到如下结论： 如果每个Counter分配4位，那么当Counter的值达到16时就会溢出。这个概率为： 这个值足够小，因此对于大多数应用程序来说，4位就足够了。 关于 CBF 中 Counter 大小的选择，主要参考这篇论文：《Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol》，在论文的第 6、7 两页专门对其做了一番阐述。 Summary Cache: A Scalable Wide-Area Web Cache Sharing Protocol 六、Bloom Filter 实现1.Guava的布隆过滤器 Guava中，布隆过滤器的实现主要涉及到2个类， BloomFilter和 BloomFilterStrategies，首先来看一下 BloomFilter的成员变量。需要注意的是不同Guava版本的 BloomFilter实现不同。 12345678/** guava实现的以CAS方式设置每个bit位的bit数组 */ private final LockFreeBitArray bits; /** hash函数的个数 */ private final int numHashFunctions; /** guava中将对象转换为byte的通道 */ private final Funnel&lt;? super T&gt; funnel; /** 将byte转换为n个bit的策略，也是bloomfilter hash映射的具体实现 */ private final Strategy strategy; 4个成员变量: LockFreeBitArray是定义在 BloomFilterStrategies中的内部类，封装了布隆过滤器底层bit数组的操作。 numHashFunctions表示哈希函数的个数。 Funnel，它和 PrimitiveSink配套使用，能将任意类型的对象转化成Java基本数据类型，默认用 java.nio.ByteBuffer实现，最终均转化为byte数组。 Strategy是定义在 BloomFilter类内部的接口，代码如下，主要有2个方法， put和 mightContain。 1234567interface Strategy extends java.io.Serializable { /** 设置元素 */ &lt;T&gt; boolean put(T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits); /** 判断元素是否存在*/ &lt;T&gt; boolean mightContain(T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits); .....} 创建布隆过滤器， BloomFilter并没有公有的构造函数，只有一个私有构造函数，而对外它提供了5个重载的 create方法，在缺省情况下误判率设定为3%，采用 BloomFilterStrategies.MURMUR128_MITZ_64的实现。 BloomFilterStrategies.MURMUR128_MITZ_64是 Strategy的两个实现之一，Guava以枚举的方式提供这两个实现，这也是《Effective Java》书中推荐的提供对象的方法之一。 12345678enum BloomFilterStrategies implements BloomFilter.Strategy { MURMUR128_MITZ_32() { //.... } MURMUR128_MITZ_64() { //.... }} 二者对应了32位哈希映射函数，和64位哈希映射函数，后者使用了murmur3 hash生成的所有128位，具有更大的空间，不过原理是相通的，我们选择相对简单的 MURMUR128_MITZ_32来分析。 先来看一下它的 put方法，它用两个hash函数来模拟多个hash函数的情况，这是布隆过滤器的一种优化。 123456789101112131415161718192021public &lt;T&gt; boolean put(T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits) { long bitSize = bits.bitSize(); // 先利用murmur3 hash对输入的funnel计算得到128位的哈希值，funnel现将object转换为byte数组， // 然后在使用哈希函数转换为long long hash64 = Hashing.murmur3_128().hashObject(object, funnel).asLong(); // 根据hash值的高低位算出hash1和hash2 int hash1 = (int) hash64; int hash2 = (int) (hash64 &gt;&gt;&gt; 32); boolean bitsChanged = false; // 循环体内采用了2个函数模拟其他函数的思想,相当于每次累加hash2 for (int i = 1; i &lt;= numHashFunctions; i++) { int combinedHash = hash1 + (i * hash2); // 如果是负数就变为正数 if (combinedHash &lt; 0) { combinedHash = ~combinedHash; } // 通过基于bitSize取模的方式获取bit数组中的索引，然后调用set函数设置。 bitsChanged |= bits.set(combinedHash % bitSize); } return bitsChanged; } 在 put方法中，先是将索引位置上的二进制置为1，然后用 bitsChanged记录插入结果，如果返回true表明没有重复插入成功，而 mightContain方法则是将索引位置上的数值取出，并判断是否为0，只要其中出现一个0，那么立即判断为不存在。 123456789101112131415161718public &lt;T&gt; boolean mightContain(T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits) { long bitSize = bits.bitSize(); long hash64 = Hashing.murmur3_128().hashObject(object, funnel).asLong(); int hash1 = (int) hash64; int hash2 = (int) (hash64 &gt;&gt;&gt; 32); for (int i = 1; i &lt;= numHashFunctions; i++) { int combinedHash = hash1 + (i * hash2); // Flip all the bits if it's negative (guaranteed positive number) if (combinedHash &lt; 0) { combinedHash = ~combinedHash; } // 和put的区别就在这里，从set转换为get，来判断是否存在 if (!bits.get(combinedHash % bitSize)) { return false; } } return true;} Guava为了提供效率，自己实现了 LockFreeBitArray来提供bit数组的无锁设置和读取。我们只来看一下它的 set函数。 123456789101112131415161718192021boolean set(long bitIndex) { if (get(bitIndex)) { return false; } int longIndex = (int) (bitIndex &gt;&gt;&gt; LONG_ADDRESSABLE_BITS); long mask = 1L &lt;&lt; bitIndex; // only cares about low 6 bits of bitIndex long oldValue; long newValue; // 经典的CAS自旋重试机制 do { oldValue = data.get(longIndex); newValue = oldValue | mask; if (oldValue == newValue) { return false; } } while (!data.compareAndSet(longIndex, oldValue, newValue)); bitCount.increment(); return true;} 2.maven引入guava包：12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt; 3.代码逻辑测试分两步： 1、往过滤器中放一百万个数，然后去验证这一百万个数是否能通过过滤器 2、另外找一万个数，去检验漏网之鱼的数量 12345678910111213141516171819202122232425262728293031323334/** * 测试布隆过滤器(可用于redis缓存穿透) * * @author 敖丙 */public class TestBloomFilter { private static int total = 1000000; private static BloomFilter&lt;Integer&gt; bf = BloomFilter.create(Funnels.integerFunnel(), total); //private static BloomFilter&lt;Integer&gt; bf = BloomFilter.create(Funnels.integerFunnel(), total, 0.001); public static void main(String[] args) { // 初始化1000000条数据到过滤器中 for (int i = 0; i &lt; total; i++) { bf.put(i); } // 匹配已在过滤器中的值，是否有匹配不上的 for (int i = 0; i &lt; total; i++) { if (!bf.mightContain(i)) { System.out.println(\"有坏人逃脱了~~~\"); } } // 匹配不在过滤器中的10000个值，有多少匹配出来 int count = 0; for (int i = total; i &lt; total + 10000; i++) { if (bf.mightContain(i)) { count++; } } System.out.println(\"误伤的数量：\" + count); }} 运行结果： 运行结果显示，遍历这一百万个在过滤器中的数时，都能被识别出来，没有一个遗漏。遍历一万个不在过滤器中的数，误伤了320个，错误率是0.032左右。 看下BloomFilter的源码： 1234567891011121314151617public static &lt;T&gt; BloomFilter&lt;T&gt; create(Funnel&lt;? super T&gt; funnel, int expectedInsertions) { return create(funnel, (long) expectedInsertions);} public static &lt;T&gt; BloomFilter&lt;T&gt; create(Funnel&lt;? super T&gt; funnel, long expectedInsertions) { return create(funnel, expectedInsertions, 0.03); // FYI, for 3%, we always get 5 hash functions}public static &lt;T&gt; BloomFilter&lt;T&gt; create( Funnel&lt;? super T&gt; funnel, long expectedInsertions, double fpp) { return create(funnel, expectedInsertions, fpp, BloomFilterStrategies.MURMUR128_MITZ_64);}static &lt;T&gt; BloomFilter&lt;T&gt; create( Funnel&lt;? super T&gt; funnel, long expectedInsertions, double fpp, Strategy strategy) { ......} BloomFilter一共四个create方法，不过最终都是走向第四个。看一下每个参数的含义： funnel：数据类型(一般是调用Funnels工具类) expectedInsertions：期望插入的值的个数 fpp 错误率(默认值为0.03) strategy 哈希算法(我也不懂啥意思)Bloom Filter的应用 在最后一个create方法中，设置一个断点： 上面的numBits，表示存一百万个int类型数字，需要的位数为7298440，700多万位。理论上存一百万个数，一个int是4字节32位，需要481000000=3200万位。如果使用HashMap去存，按HashMap50%的存储效率，需要6400万位。可以看出BloomFilter的存储空间很小，只有HashMap的1/10左右 上面的numHashFunctions，表示需要5个函数去存这些数字 使用第三个create方法，我们设置下错误率： 1private static BloomFilter&lt;Integer&gt; bf = BloomFilter.create(Funnels.integerFunnel(), total, 0.001); 再运行看看： 此时误伤的数量为19，错误率为0.0019左右。 当错误率设为0.001时，所需要的位数为14377587，1400万位，需要10个函数。 和上面对比可以看出，错误率越大，所需空间和时间越小，错误率越小，所需空间和时间约大。 参考文章： Bloom Filter概念和原理 Bloom Filter 算法简介 (增加 Counting Bloom Filter 内容) Redis-避免缓存穿透的利器之BloomFilter Guava的布隆过滤器原来是这么回事儿 #","link":"/2020/01/13/BloomFilter算法/"},{"title":"『转』Guava RateLimiter限流原理解析","text":"转载自：超详细的Guava RateLimiter限流原理解析 限流是保护高并发系统的三把利器之一，另外两个是缓存和降级。限流在很多场景中用来限制并发和请求量，比如说秒杀抢购，保护自身系统和下游系统不被巨型流量冲垮等。 限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务或进行流量整形。 常用的限流方式和场景有：限制总并发数（比如数据库连接池、线程池）、限制瞬时并发数（如nginx的limitconn模块，用来限制瞬时并发连接数，Java的Semaphore也可以实现）、限制时间窗口内的平均速率（如Guava的RateLimiter、nginx的limitreq模块，限制每秒的平均速率）；其他还有如限制远程接口调用速率、限制MQ的消费速率。另外还可以根据网络连接数、网络流量、CPU或内存负载等来限流。 比如说，我们需要限制方法被调用的并发数不能超过100（同一时间并发数），则我们可以用信号量 Semaphore实现。可如果我们要限制方法在一段时间内平均被调用次数不超过100，则需要使用 RateLimiter。 限流的基础算法 我们先来讲解一下两个限流相关的基本算法：漏桶算法和令牌桶算法。 从上图中，我们可以看到，就像一个漏斗一样，进来的水量就好像访问流量一样，而出去的水量就像是我们的系统处理请求一样。当访问流量过大时，这个漏斗中就会积水，如果水太多了就会溢出。 漏桶算法的实现往往依赖于队列，请求到达如果队列未满则直接放入队列，然后有一个处理器按照固定频率从队列头取出请求进行处理。如果请求量大，则会导致队列满，那么新来的请求就会被抛弃。 令牌桶算法则是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。桶中存放的令牌数有最大上限，超出之后就被丢弃或者拒绝。当流量或者网络请求到达时，每个请求都要获取一个令牌，如果能够获取到，则直接处理，并且令牌桶删除一个令牌。如果获取不同，该请求就要被限流，要么直接丢弃，要么在缓冲区等待。 令牌桶和漏桶对比： 令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求；漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝； 令牌桶限制的是平均流入速率，允许突发请求，只要有令牌就可以处理，支持一次拿3个令牌，4个令牌；漏桶限制的是常量流出速率，即流出速率是一个固定常量值，比如都是1的速率流出，而不能一次是1，下次又是2，从而平滑突发流入速率； 令牌桶允许一定程度的突发，而漏桶主要目的是平滑流出速率； Guava RateLimiter Guava是Java领域优秀的开源项目，它包含了Google在Java项目中使用一些核心库，包含集合(Collections)，缓存(Caching)，并发编程库(Concurrency)，常用注解(Common annotations)，String操作，I/O操作方面的众多非常实用的函数。 Guava的 RateLimiter提供了令牌桶算法实现：平滑突发限流(SmoothBursty)和平滑预热限流(SmoothWarmingUp)实现。 RateLimiter的类图如上所示，其中 RateLimiter是入口类，它提供了两套工厂方法来创建出两个子类。这很符合《Effective Java》中的用静态工厂方法代替构造函数的建议，毕竟该书的作者也正是Guava库的主要维护者，二者配合”食用”更佳。 123456789101112// RateLimiter提供了两个工厂方法，最终会调用下面两个函数，生成RateLimiter的两个子类。static RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) { RateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 /* maxBurstSeconds */); rateLimiter.setRate(permitsPerSecond); return rateLimiter;}static RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond, long warmupPeriod, TimeUnit unit, double coldFactor) { RateLimiter rateLimiter = new SmoothWarmingUp(stopwatch, warmupPeriod, unit, coldFactor); rateLimiter.setRate(permitsPerSecond); return rateLimiter;} 平滑突发限流 使用 RateLimiter的静态方法创建一个限流器，设置每秒放置的令牌数为5个。返回的RateLimiter对象可以保证1秒内不会给超过5个令牌，并且以固定速率进行放置，达到平滑输出的效果。 12345678910111213141516public void testSmoothBursty() { RateLimiter r = RateLimiter.create(5); while (true) { System.out.println(\"get 1 tokens: \" + r.acquire() + \"s\"); } /** * output: 基本上都是0.2s执行一次，符合一秒发放5个令牌的设定。 * get 1 tokens: 0.0s * get 1 tokens: 0.182014s * get 1 tokens: 0.188464s * get 1 tokens: 0.198072s * get 1 tokens: 0.196048s * get 1 tokens: 0.197538s * get 1 tokens: 0.196049s */} RateLimiter使用令牌桶算法，会进行令牌的累积，如果获取令牌的频率比较低，则不会导致等待，直接获取令牌。 1234567891011121314151617181920212223242526public void testSmoothBursty2() { RateLimiter r = RateLimiter.create(2); while (true) { System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); try { Thread.sleep(2000); } catch (Exception e) { } System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"end\"); /** * output: * get 1 tokens: 0.0s * get 1 tokens: 0.0s * get 1 tokens: 0.0s * get 1 tokens: 0.0s * end * get 1 tokens: 0.499796s * get 1 tokens: 0.0s * get 1 tokens: 0.0s * get 1 tokens: 0.0s */ } } RateLimiter由于会累积令牌，所以可以应对突发流量。在下面代码中，有一个请求会直接请求5个令牌，但是由于此时令牌桶中有累积的令牌，足以快速响应。 RateLimiter在没有足够令牌发放时，采用滞后处理的方式，也就是前一个请求获取令牌所需等待的时间由下一次请求来承受，也就是代替前一个请求进行等待。 12345678910111213141516171819202122public void testSmoothBursty3() { RateLimiter r = RateLimiter.create(5); while (true) { System.out.println(\"get 5 tokens: \" + r.acquire(5) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"end\"); /** * output: * get 5 tokens: 0.0s * get 1 tokens: 0.996766s 滞后效应，需要替前一个请求进行等待 * get 1 tokens: 0.194007s * get 1 tokens: 0.196267s * end * get 5 tokens: 0.195756s * get 1 tokens: 0.995625s 滞后效应，需要替前一个请求进行等待 * get 1 tokens: 0.194603s * get 1 tokens: 0.196866s */ } } 平滑预热限流 RateLimiter的 SmoothWarmingUp是带有预热期的平滑限流，它启动后会有一段预热期，逐步将分发频率提升到配置的速率。 比如下面代码中的例子，创建一个平均分发令牌速率为2，预热期为3分钟。由于设置了预热时间是3秒，令牌桶一开始并不会0.5秒发一个令牌，而是形成一个平滑线性下降的坡度，频率越来越高，在3秒钟之内达到原本设置的频率，以后就以固定的频率输出。这种功能适合系统刚启动需要一点时间来“热身”的场景。 12345678910111213141516171819202122public void testSmoothwarmingUp() { RateLimiter r = RateLimiter.create(2, 3, TimeUnit.SECONDS); while (true) { System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"get 1 tokens: \" + r.acquire(1) + \"s\"); System.out.println(\"end\"); /** * output: * get 1 tokens: 0.0s * get 1 tokens: 1.329289s * get 1 tokens: 0.994375s * get 1 tokens: 0.662888s 上边三次获取的时间相加正好为3秒 * end * get 1 tokens: 0.49764s 正常速率0.5秒一个令牌 * get 1 tokens: 0.497828s * get 1 tokens: 0.49449s * get 1 tokens: 0.497522s */ } } 源码分析 看完了 RateLimiter的基本使用示例后，我们来学习一下它的实现原理。先了解一下几个比较重要的成员变量的含义。 1//SmoothRateLimiter.java//当前存储令牌数double storedPermits;//最大存储令牌数double maxPermits;//添加令牌时间间隔double stableIntervalMicros;/** * 下一次请求可以获取令牌的起始时间 * 由于RateLimiter允许预消费，上次请求预消费令牌后 * 下次请求需要等待相应的时间到nextFreeTicketMicros时刻才可以获取令牌 */private long nextFreeTicketMicros = 0L; 平滑突发限流 RateLimiter的原理就是每次调用 acquire时用当前时间和 nextFreeTicketMicros进行比较，根据二者的间隔和添加单位令牌的时间间隔 stableIntervalMicros来刷新存储令牌数 storedPermits。然后acquire会进行休眠，直到 nextFreeTicketMicros。 acquire函数如下所示，它会调用 reserve函数计算获取目标令牌数所需等待的时间，然后使用 SleepStopwatch进行休眠，最后返回等待时间。 123456789101112131415161718192021public double acquire(int permits) { // 计算获取令牌所需等待的时间 long microsToWait = reserve(permits); // 进行线程sleep stopwatch.sleepMicrosUninterruptibly(microsToWait); return 1.0 * microsToWait / SECONDS.toMicros(1L);}final long reserve(int permits) { checkPermits(permits); // 由于涉及并发操作，所以使用synchronized进行并发操作 synchronized (mutex()) { return reserveAndGetWaitLength(permits, stopwatch.readMicros()); }}final long reserveAndGetWaitLength(int permits, long nowMicros) { // 计算从当前时间开始，能够获取到目标数量令牌时的时间 long momentAvailable = reserveEarliestAvailable(permits, nowMicros); // 两个时间相减，获得需要等待的时间 return max(momentAvailable - nowMicros, 0);} reserveEarliestAvailable是刷新令牌数和下次获取令牌时间 nextFreeTicketMicros的关键函数。它有三个步骤，一是调用 resync函数增加令牌数，二是计算预支付令牌所需额外等待的时间，三是更新下次获取令牌时间 nextFreeTicketMicros和存储令牌数 storedPermits。 这里涉及 RateLimiter的一个特性，也就是可以预先支付令牌，并且所需等待的时间在下次获取令牌时再实际执行。详细的代码逻辑的解释请看注释。 1234567891011121314151617181920212223242526272829final long reserveEarliestAvailable(int requiredPermits, long nowMicros) { // 刷新令牌数，相当于每次acquire时在根据时间进行令牌的刷新 resync(nowMicros); long returnValue = nextFreeTicketMicros; // 获取当前已有的令牌数和需要获取的目标令牌数进行比较，计算出可以目前即可得到的令牌数。 double storedPermitsToSpend = min(requiredPermits, this.storedPermits); // freshPermits是需要预先支付的令牌，也就是目标令牌数减去目前即可得到的令牌数 double freshPermits = requiredPermits - storedPermitsToSpend; // 因为会突然涌入大量请求，而现有令牌数又不够用，因此会预先支付一定的令牌数 // waitMicros即是产生预先支付令牌的数量时间，则将下次要添加令牌的时间应该计算时间加上watiMicros long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); // storedPermitsToWaitTime在SmoothWarmingUp和SmoothBuresty的实现不同，用于实现预热缓冲期 // SmoothBuresty的storedPermitsToWaitTime直接返回0，所以watiMicros就是预先支付的令牌所需等待的时间 try { // 更新nextFreeTicketMicros,本次预先支付的令牌所需等待的时间让下一次请求来实际等待。 this.nextFreeTicketMicros = LongMath.checkedAdd(nextFreeTicketMicros, waitMicros); } catch (ArithmeticException e) { this.nextFreeTicketMicros = Long.MAX_VALUE; } // 更新令牌数，最低数量为0 this.storedPermits -= storedPermitsToSpend; // 返回旧的nextFreeTicketMicros数值，无需为预支付的令牌多加等待时间。 return returnValue;}// SmoothBurestlong storedPermitsToWaitTime(double storedPermits, double permitsToTake) { return 0L;} resync函数用于增加存储令牌，核心逻辑就是 (nowMicros-nextFreeTicketMicros)/stableIntervalMicros。当前时间大于 nextFreeTicketMicros时进行刷新，否则直接返回。 1void resync(long nowMicros) { // 当前时间晚于nextFreeTicketMicros，所以刷新令牌和nextFreeTicketMicros if (nowMicros &gt; nextFreeTicketMicros) { // coolDownIntervalMicros函数获取每机秒生成一个令牌，SmoothWarmingUp和SmoothBuresty的实现不同 // SmoothBuresty的coolDownIntervalMicros直接返回stableIntervalMicros // 当前时间减去要更新令牌的时间获取时间间隔，再除以添加令牌时间间隔获取这段时间内要添加的令牌数 storedPermits = min(maxPermits, storedPermits + (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros()); nextFreeTicketMicros = nowMicros; } // 如果当前时间早于nextFreeTicketMicros，则获取令牌的线程要一直等待到nextFreeTicketMicros,该线程获取令牌所需 // 额外等待的时间由下一次获取的线程来代替等待。}double coolDownIntervalMicros() { return stableIntervalMicros;} 下面我们举个例子，让大家更好的理解 resync和 reserveEarliestAvailable函数的逻辑。 比如 RateLimiter的 stableIntervalMicros为500，也就是1秒发两个令牌，storedPermits为0，nextFreeTicketMicros为155391849 5748。线程一acquire(2)，当前时间为155391849 6248，首先 resync函数计算，(1553918496248 - 1553918495748)/500 = 1，所以当前可获取令牌数为1，但是由于可以预支付，所以nextFreeTicketMicros= nextFreeTicketMicro + 1 * 500 = 155391849 6748。线程一无需等待。 紧接着，线程二也来acquire(2)，首先 resync函数发现当前时间早于 nextFreeTicketMicros，所以无法增加令牌数，所以需要预支付2个令牌，nextFreeTicketMicros= nextFreeTicketMicro + 2 * 500 = 155391849 7748。线程二需要等待155391849 6748时刻，也就是线程一获取时计算的nextFreeTicketMicros时刻。同样的，线程三获取令牌时也需要等待到线程二计算的nextFreeTicketMicros时刻。 平滑预热限流 上述就是平滑突发限流RateLimiter的实现，下面我们来看一下加上预热缓冲期的实现原理。 SmoothWarmingUp实现预热缓冲的关键在于其分发令牌的速率会随时间和令牌数而改变，速率会先慢后快。表现形式如下图所示，令牌刷新的时间间隔由长逐渐变短。等存储令牌数从maxPermits到达thresholdPermits时，发放令牌的时间价格也由coldInterval降低到了正常的stableInterval。 SmoothWarmingUp的相关代码如下所示，相关的逻辑都写在注释中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// SmoothWarmingUp，等待时间就是计算上图中梯形或者正方形的面积。long storedPermitsToWaitTime(double storedPermits, double permitsToTake) { /** * 当前permits超出阈值的部分 */ double availablePermitsAboveThreshold = storedPermits - thresholdPermits; long micros = 0; /** * 如果当前存储的令牌数超出thresholdPermits */ if (availablePermitsAboveThreshold &gt; 0.0) { /** * 在阈值右侧并且需要被消耗的令牌数量 */ double permitsAboveThresholdToTake = min(availablePermitsAboveThreshold, permitsToTake); /** * 梯形的面积 * * 高 * (顶 * 底) / 2 * * 高是 permitsAboveThresholdToTake 也就是右侧需要消费的令牌数 * 底 较长 permitsToTime(availablePermitsAboveThreshold) * 顶 较短 permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake) */ micros = (long) (permitsAboveThresholdToTake * (permitsToTime(availablePermitsAboveThreshold) + permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake)) / 2.0); /** * 减去已经获取的在阈值右侧的令牌数 */ permitsToTake -= permitsAboveThresholdToTake; } /** * 平稳时期的面积，正好是长乘宽 */ micros += (stableIntervalMicros * permitsToTake); return micros;}double coolDownIntervalMicros() { /** * 每秒增加的令牌数为 warmup时间/maxPermits. 这样的话，在warmuptime时间内，就就增张的令牌数量 * 为 maxPermits */ return warmupPeriodMicros / maxPermits;} 后记 RateLimiter只能用于单机的限流，如果想要集群限流，则需要引入 redis或者阿里开源的 sentinel中间件，请大家继续关注。","link":"/2020/01/14/GuavaRateLimiter限流原理解析/"},{"title":"logback模板整理","text":"记录开发过程中的日志模板 项目日志模板123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;logger name=\"leap.core.DefaultAppConfigSource\" level=\"WARN\"/&gt; &lt;logger name=\"leap.core.DefaultAppHome\" level=\"WARN\"/&gt; &lt;logger name=\"leap.web.DefaultAppHandler\" level=\"WARN\"/&gt; &lt;logger name=\"leap.web.AppBootstrap\" level=\"WARN\"/&gt; &lt;logger name=\"leap.db\" level=\"DEBUG\"/&gt; &lt;include resource=\"org/springframework/boot/logging/logback/base.xml\" /&gt; &lt;!--输出sql语句--&gt; &lt;logger name=\"app\" level=\"debug\"/&gt; &lt;property name=\"path\" value=\"./logs/\"&gt;&lt;/property&gt; &lt;property name=\"maxHistory\" value=\"30\"/&gt; &lt;property name=\"maxFileSize\" value=\"10MB\"/&gt; &lt;appender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%date | %level | %logger [%file : %line] - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"debug_file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;${path}/logback_debug.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 每天一归档 --&gt; &lt;fileNamePattern&gt;${path}/logback_debug.%d{yyyy-MM-dd}-%i.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date | %level | %logger [%file : %line] - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=\"info_file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;${path}/logback_info.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 每天一归档 --&gt; &lt;fileNamePattern&gt;${path}/logback_info.%d{yyyy-MM-dd}-%i.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date | %level | %logger [%file : %line] - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=\"warn_file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;${path}/logback_warn.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 每天一归档 --&gt; &lt;fileNamePattern&gt;${path}/logback_warn.%d{yyyy-MM-dd}-%i.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date | %level | %logger [%file : %line] - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=\"error_file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;${path}/logback_error.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 每天一归档 --&gt; &lt;fileNamePattern&gt;${path}/logback_error.%d{yyyy-MM-dd}-%i.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;${maxHistory}&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;${maxFileSize}&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%date | %level | %logger [%file : %line] - %msg%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 级别依次为【从高到低】：FATAL &gt; ERROR &gt; WARN &gt; INFO &gt; DEBUG &gt; TRACE --&gt; &lt;!--&lt;root&gt;--&gt; &lt;!--&lt;level value=\"info\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"console\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"debug_file\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"info_file\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"warn_file\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"error_file\"/&gt;--&gt; &lt;!--&lt;/root&gt;--&gt; &lt;logger name=\"app\" level=\"TRACE\"&gt; &lt;appender-ref ref=\"console\"/&gt; &lt;appender-ref ref=\"debug_file\"/&gt; &lt;appender-ref ref=\"info_file\"/&gt; &lt;appender-ref ref=\"warn_file\"/&gt; &lt;appender-ref ref=\"error_file\"/&gt; &lt;/logger&gt;&lt;/configuration&gt; 自己整理的模板123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!-- 日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --&gt;&lt;!-- scan:当此属性设置为true时，配置文档如果发生改变，将会被重新加载，默认值为true --&gt;&lt;!-- scanPeriod:设置监测配置文档是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。 当scan为true时，此属性生效。默认的时间间隔为1分钟。 --&gt;&lt;!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --&gt;&lt;configuration scan=\"true\" scanPeriod=\"10 seconds\"&gt; &lt;contextName&gt;logback-spring&lt;/contextName&gt; &lt;!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义后，可以使“${}”来使用变量。 --&gt; &lt;!-- 定义日志的根目录 --&gt; &lt;property name=\"LOG_HOME\" value=\"./logs\" /&gt; &lt;!-- 定义日志文件名称 --&gt; &lt;property name=\"APP_NAME\" value=\"yuexiu-questionnaire\"&gt;&lt;/property&gt; &lt;!--0. 日志格式和颜色渲染 --&gt; &lt;!-- 彩色日志依赖的渲染类 --&gt; &lt;conversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\"/&gt; &lt;conversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\"/&gt; &lt;conversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\"/&gt; &lt;!-- 彩色日志格式 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%4.100t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\"/&gt; &lt;!--1. 输出到控制台--&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;!--&lt;pattern&gt;%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(%5p) %clr(-&amp;#45;&amp;#45;){faint} %clr(%-80.80logger{79}){cyan} %clr(:){faint} %m%n&lt;/pattern&gt;--&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;!-- 设置字符集 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--2. 输出到文档--&gt; &lt;!-- 2.1 level为 DEBUG 日志，时间滚动输出 --&gt; &lt;appender name=\"DEBUG_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;${LOG_HOME}/${APP_NAME}_debug.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${LOG_HOME}/${APP_NAME}-debug-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;180&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录debug级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;debug&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.2 level为 INFO 日志，时间滚动输出 --&gt; &lt;appender name=\"INFO_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;${LOG_HOME}/${APP_NAME}_info.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 每天日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${LOG_HOME}/${APP_NAME}-info-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;180&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录info级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;info&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.3 level为 WARN 日志，时间滚动输出 --&gt; &lt;appender name=\"WARN_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;${LOG_HOME}/${APP_NAME}_warn.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;${LOG_HOME}/${APP_NAME}-warn-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;180&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录warn级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;warn&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.4 level为 ERROR 日志，时间滚动输出 --&gt; &lt;appender name=\"ERROR_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;${LOG_HOME}/${APP_NAME}_error.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;${LOG_HOME}/${APP_NAME}-error-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;180&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录ERROR级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 2.5 level为 TRACE 日志，时间滚动输出 --&gt; &lt;appender name=\"TRACE_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 正在记录的日志文档的路径及文档名 --&gt; &lt;file&gt;${LOG_HOME}/${APP_NAME}_trace.log&lt;/file&gt; &lt;!--日志文档输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档 --&gt; &lt;fileNamePattern&gt;${LOG_HOME}/${APP_NAME}-trace-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文档保留天数--&gt; &lt;maxHistory&gt;180&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文档只记录debug级别的 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.LevelFilter\"&gt; &lt;level&gt;trace&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- &lt;logger&gt;用来设置某一个包或者具体的某一个类的日志打印级别、 以及指定&lt;appender&gt;。&lt;logger&gt;仅有一个name属性， 一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 &lt;logger name=\"org.springframework.web\" level=\"info\"/&gt; &lt;logger name=\"org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor\" level=\"INFO\"/&gt; --&gt; &lt;!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里我们只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种把&lt;root level=\"info\"&gt;改成&lt;root level=\"DEBUG\"&gt;这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种就是单独给dao下目录配置debug模式，代码如下，这样配置sql语句会打印，其他还是正常info级别： 【logging.level.org.mybatis=debug logging.level.dao=debug】 --&gt; &lt;!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 不能设置为INHERITED或者同义词NULL。默认是DEBUG 可以包含零个或多个元素，标识这个appender将会添加到这个logger。 --&gt; &lt;!-- 4. 最终的策略 --&gt; &lt;!-- 4.1 开发环境:打印控制台--&gt; &lt;springProfile name=\"dev\"&gt; &lt;root level=\"info\"&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;appender-ref ref=\"TRACE_FILE\"/&gt; &lt;appender-ref ref=\"DEBUG_FILE\"/&gt; &lt;appender-ref ref=\"INFO_FILE\"/&gt; &lt;appender-ref ref=\"WARN_FILE\"/&gt; &lt;appender-ref ref=\"ERROR_FILE\"/&gt; &lt;/root&gt; &lt;/springProfile&gt; &lt;!-- 4.2 生产环境:输出到文档--&gt; &lt;springProfile name=\"test,prod\"&gt; &lt;root level=\"error\"&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;appender-ref ref=\"TRACE_FILE\"/&gt; &lt;appender-ref ref=\"DEBUG_FILE\"/&gt; &lt;appender-ref ref=\"INFO_FILE\"/&gt; &lt;appender-ref ref=\"ERROR_FILE\"/&gt; &lt;appender-ref ref=\"WARN_FILE\"/&gt; &lt;/root&gt; &lt;/springProfile&gt;&lt;/configuration&gt;","link":"/2019/08/08/logback模板整理/"},{"title":"SpringBoot Redis工具类封装","text":"一、Maven依赖1、本文所采用的SpringBoot的版本如下123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; 2、加入Redis相关依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 二、application.properties中加入redis相关配置123456789101112131415161718# Redis数据库索引（默认为0） spring.redis.database=0 # Redis服务器地址 spring.redis.host=192.168.0.24 # Redis服务器连接端口 spring.redis.port=6379 # Redis服务器连接密码（默认为空） spring.redis.password= # 连接池最大连接数（使用负值表示没有限制） spring.redis.pool.max-active=200 # 连接池最大阻塞等待时间（使用负值表示没有限制） spring.redis.pool.max-wait=-1 # 连接池中的最大空闲连接 spring.redis.pool.max-idle=10 # 连接池中的最小空闲连接 spring.redis.pool.min-idle=0 # 连接超时时间（毫秒） spring.redis.timeout=1000 三、Redis配置类1、默认RedisTemplate的自动配置其实现在就可以在代码中注入RedisTemplate，为啥可以直接注入呢？先看下源码吧。下图为 RedisAutoConfiguration类中的代码： 1234567891011121314151617181920212223@Configuration@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)@Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class })public class RedisAutoConfiguration { @Bean @ConditionalOnMissingBean(name = \"redisTemplate\") public RedisTemplate&lt;Object, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; }} 通过源码可以看出，SpringBoot自动帮我们在容器中生成了一个RedisTemplate和一个StringRedisTemplate。但是，这个RedisTemplate的泛型是&lt;Object,Object&gt;，写代码不方便，需要写好多类型转换的代码；我们需要一个泛型为&lt;String,Object&gt;形式的RedisTemplate。并且，这个RedisTemplate没有设置数据存在Redis时，key及value的序列化方式。 看到这个@ConditionalOnMissingBean注解后，就知道如果Spring容器中有了RedisTemplate对象了，这个自动配置的RedisTemplate不会实例化。因此我们可以直接自己写个配置类，配置RedisTemplate。 2、自动配置不好用，重新配置一个RedisTemplate123456789101112131415161718192021222324252627282930313233343536373839404142import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer; /** * redis配置类 * @author zhangzhixiang * @date 2019年06月19日 * */@Configurationpublic class RedisConfig { @Bean @SuppressWarnings(\"all\") public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) { RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;String, Object&gt;(); template.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); // hash的key也采用String的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value序列化方式采用jackson template.setValueSerializer(jackson2JsonRedisSerializer); // hash的value序列化方式采用jackson template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; }} 四、Redis工具类直接用RedisTemplate操作Redis，需要很多行代码，因此直接封装好一个RedisUtils，这样写代码更方便点。这个RedisUtils交给Spring容器实例化，使用时直接注解注入。 工具类代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Component;import org.springframework.util.CollectionUtils; import java.util.List;import java.util.Map;import java.util.Set;import java.util.concurrent.TimeUnit; /** * Redis工具类 * * @author zhangzhixiang * @date 2019年06月19日 */@Componentpublic final class RedisUtil { @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; // =============================common============================ /** * 指定缓存失效时间 * * @param key 键 * @param time 时间(秒) * @return */ public boolean expire(String key, long time) { try { if (time &gt; 0) { redisTemplate.expire(key, time, TimeUnit.SECONDS); } return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 根据key 获取过期时间 * * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ public long getExpire(String key) { return redisTemplate.getExpire(key, TimeUnit.SECONDS); } /** * 判断key是否存在 * * @param key 键 * @return true 存在 false不存在 */ public boolean hasKey(String key) { try { return redisTemplate.hasKey(key); } catch (Exception e) { e.printStackTrace(); return false; } } /** * 删除缓存 * * @param key 可以传一个值 或多个 */ @SuppressWarnings(\"unchecked\") public void del(String... key) { if (key != null &amp;&amp; key.length &gt; 0) { if (key.length == 1) { redisTemplate.delete(key[0]); } else { redisTemplate.delete(CollectionUtils.arrayToList(key)); } } } // ============================String============================= /** * 普通缓存获取 * * @param key 键 * @return 值 */ public Object get(String key) { return key == null ? null : redisTemplate.opsForValue().get(key); } /** * 普通缓存放入 * * @param key 键 * @param value 值 * @return true成功 false失败 */ public boolean set(String key, Object value) { try { redisTemplate.opsForValue().set(key, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 普通缓存放入并设置时间 * * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 * @return true成功 false 失败 */ public boolean set(String key, Object value, long time) { try { if (time &gt; 0) { redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS); } else { set(key, value); } return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 递增 * * @param key 键 * @param delta 要增加几(大于0) * @return */ public long incr(String key, long delta) { if (delta &lt; 0) { throw new RuntimeException(\"递增因子必须大于0\"); } return redisTemplate.opsForValue().increment(key, delta); } /** * 递减 * * @param key 键 * @param delta 要减少几(小于0) * @return */ public long decr(String key, long delta) { if (delta &lt; 0) { throw new RuntimeException(\"递减因子必须大于0\"); } return redisTemplate.opsForValue().increment(key, -delta); } // ================================Map================================= /** * HashGet * * @param key 键 不能为null * @param item 项 不能为null * @return 值 */ public Object hget(String key, String item) { return redisTemplate.opsForHash().get(key, item); } /** * 获取hashKey对应的所有键值 * * @param key 键 * @return 对应的多个键值 */ public Map&lt;Object, Object&gt; hmget(String key) { return redisTemplate.opsForHash().entries(key); } /** * HashSet * * @param key 键 * @param map 对应多个键值 * @return true 成功 false 失败 */ public boolean hmset(String key, Map&lt;String, Object&gt; map) { try { redisTemplate.opsForHash().putAll(key, map); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * HashSet 并设置时间 * * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) * @return true成功 false失败 */ public boolean hmset(String key, Map&lt;String, Object&gt; map, long time) { try { redisTemplate.opsForHash().putAll(key, map); if (time &gt; 0) { expire(key, time); } return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @return true 成功 false失败 */ public boolean hset(String key, String item, Object value) { try { redisTemplate.opsForHash().put(key, item, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 * @return true 成功 false失败 */ public boolean hset(String key, String item, Object value, long time) { try { redisTemplate.opsForHash().put(key, item, value); if (time &gt; 0) { expire(key, time); } return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 删除hash表中的值 * * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ public void hdel(String key, Object... item) { redisTemplate.opsForHash().delete(key, item); } /** * 判断hash表中是否有该项的值 * * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ public boolean hHasKey(String key, String item) { return redisTemplate.opsForHash().hasKey(key, item); } /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * * @param key 键 * @param item 项 * @param by 要增加几(大于0) * @return */ public double hincr(String key, String item, double by) { return redisTemplate.opsForHash().increment(key, item, by); } /** * hash递减 * * @param key 键 * @param item 项 * @param by 要减少记(小于0) * @return */ public double hdecr(String key, String item, double by) { return redisTemplate.opsForHash().increment(key, item, -by); } // ============================set============================= /** * 根据key获取Set中的所有值 * * @param key 键 * @return */ public Set&lt;Object&gt; sGet(String key) { try { return redisTemplate.opsForSet().members(key); } catch (Exception e) { e.printStackTrace(); return null; } } /** * 根据value从一个set中查询,是否存在 * * @param key 键 * @param value 值 * @return true 存在 false不存在 */ public boolean sHasKey(String key, Object value) { try { return redisTemplate.opsForSet().isMember(key, value); } catch (Exception e) { e.printStackTrace(); return false; } } /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ public long sSet(String key, Object... values) { try { return redisTemplate.opsForSet().add(key, values); } catch (Exception e) { e.printStackTrace(); return 0; } } /** * 将set数据放入缓存 * * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ public long sSetAndTime(String key, long time, Object... values) { try { Long count = redisTemplate.opsForSet().add(key, values); if (time &gt; 0) expire(key, time); return count; } catch (Exception e) { e.printStackTrace(); return 0; } } /** * 获取set缓存的长度 * * @param key 键 * @return */ public long sGetSetSize(String key) { try { return redisTemplate.opsForSet().size(key); } catch (Exception e) { e.printStackTrace(); return 0; } } /** * 移除值为value的 * * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ public long setRemove(String key, Object... values) { try { Long count = redisTemplate.opsForSet().remove(key, values); return count; } catch (Exception e) { e.printStackTrace(); return 0; } } // ===============================list================================= /** * 获取list缓存的内容 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return */ public List&lt;Object&gt; lGet(String key, long start, long end) { try { return redisTemplate.opsForList().range(key, start, end); } catch (Exception e) { e.printStackTrace(); return null; } } /** * 获取list缓存的长度 * * @param key 键 * @return */ public long lGetListSize(String key) { try { return redisTemplate.opsForList().size(key); } catch (Exception e) { e.printStackTrace(); return 0; } } /** * 通过索引 获取list中的值 * * @param key 键 * @param index 索引 index&gt;=0时， 0 表头，1 第二个元素，依次类推；index&lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return */ public Object lGetIndex(String key, long index) { try { return redisTemplate.opsForList().index(key, index); } catch (Exception e) { e.printStackTrace(); return null; } } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @return */ public boolean lSet(String key, Object value) { try { redisTemplate.opsForList().rightPush(key, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ public boolean lSet(String key, Object value, long time) { try { redisTemplate.opsForList().rightPush(key, value); if (time &gt; 0) expire(key, time); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @return */ public boolean lSet(String key, List&lt;Object&gt; value) { try { redisTemplate.opsForList().rightPushAll(key, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ public boolean lSet(String key, List&lt;Object&gt; value, long time) { try { redisTemplate.opsForList().rightPushAll(key, value); if (time &gt; 0) expire(key, time); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 根据索引修改list中的某条数据 * * @param key 键 * @param index 索引 * @param value 值 * @return */ public boolean lUpdateIndex(String key, long index, Object value) { try { redisTemplate.opsForList().set(key, index, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } /** * 移除N个值为value * * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ public long lRemove(String key, long count, Object value) { try { Long remove = redisTemplate.opsForList().remove(key, count, value); return remove; } catch (Exception e) { e.printStackTrace(); return 0; } }} 五、默认注入的RedisTemplate源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892package org.springframework.data.redis.core;import java.io.Closeable;import java.lang.reflect.Proxy;import java.util.ArrayList;import java.util.Collection;import java.util.Collections;import java.util.Date;import java.util.Iterator;import java.util.LinkedHashSet;import java.util.List;import java.util.Map;import java.util.Set;import java.util.concurrent.TimeUnit;import org.springframework.beans.factory.BeanClassLoaderAware;import org.springframework.dao.DataAccessException;import org.springframework.dao.InvalidDataAccessApiUsageException;import org.springframework.data.redis.connection.DataType;import org.springframework.data.redis.connection.RedisConnection;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.SortParameters;import org.springframework.data.redis.connection.RedisZSetCommands.Tuple;import org.springframework.data.redis.core.ZSetOperations.TypedTuple;import org.springframework.data.redis.core.query.QueryUtils;import org.springframework.data.redis.core.query.SortQuery;import org.springframework.data.redis.core.script.DefaultScriptExecutor;import org.springframework.data.redis.core.script.RedisScript;import org.springframework.data.redis.core.script.ScriptExecutor;import org.springframework.data.redis.core.types.RedisClientInfo;import org.springframework.data.redis.serializer.JdkSerializationRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.data.redis.serializer.SerializationUtils;import org.springframework.data.redis.serializer.StringRedisSerializer;import org.springframework.transaction.support.TransactionSynchronizationManager;import org.springframework.util.Assert;import org.springframework.util.ClassUtils;import org.springframework.util.CollectionUtils;public class RedisTemplate&lt;K, V&gt; extends RedisAccessor implements RedisOperations&lt;K, V&gt;, BeanClassLoaderAware { private boolean enableTransactionSupport = false; private boolean exposeConnection = false; private boolean initialized = false; private boolean enableDefaultSerializer = true; private RedisSerializer&lt;?&gt; defaultSerializer; private ClassLoader classLoader; private RedisSerializer keySerializer = null; private RedisSerializer valueSerializer = null; private RedisSerializer hashKeySerializer = null; private RedisSerializer hashValueSerializer = null; private RedisSerializer&lt;String&gt; stringSerializer = new StringRedisSerializer(); private ScriptExecutor&lt;K&gt; scriptExecutor; private ValueOperations&lt;K, V&gt; valueOps; private ListOperations&lt;K, V&gt; listOps; private SetOperations&lt;K, V&gt; setOps; private ZSetOperations&lt;K, V&gt; zSetOps; private GeoOperations&lt;K, V&gt; geoOps; private HyperLogLogOperations&lt;K, V&gt; hllOps; public RedisTemplate() { } //afterPropertiesSet （初始化操作）加载配置后执行 public void afterPropertiesSet() { super.afterPropertiesSet(); boolean defaultUsed = false; //serializer 序列化 if (this.defaultSerializer == null) { this.defaultSerializer = new JdkSerializationRedisSerializer(this.classLoader != null ? this.classLoader : this.getClass().getClassLoader()); } //enable 使能够，提供做…的权利[措施]; 使可能; 授予权利或方法; if (this.enableDefaultSerializer) { if (this.keySerializer == null) { this.keySerializer = this.defaultSerializer; defaultUsed = true; } if (this.valueSerializer == null) { this.valueSerializer = this.defaultSerializer; defaultUsed = true; } if (this.hashKeySerializer == null) { this.hashKeySerializer = this.defaultSerializer; defaultUsed = true; } if (this.hashValueSerializer == null) { this.hashValueSerializer = this.defaultSerializer; defaultUsed = true; } } if (this.enableDefaultSerializer &amp;&amp; defaultUsed) { Assert.notNull(this.defaultSerializer, \"default serializer null and not all serializers initialized\"); } //script脚本 //Executor 遗嘱执行人; 执行者; 实行者; if (this.scriptExecutor == null) { this.scriptExecutor = new DefaultScriptExecutor(this); } //初始化完成 this.initialized = true; } //execute 执行 exposeConnection暴露连接 public &lt;T&gt; T execute(RedisCallback&lt;T&gt; action) { return this.execute(action, this.isExposeConnection()); } public &lt;T&gt; T execute(RedisCallback&lt;T&gt; action, boolean exposeConnection) { return this.execute(action, exposeConnection, false); } //pipeline 管道 public &lt;T&gt; T execute(RedisCallback&lt;T&gt; action, boolean exposeConnection, boolean pipeline) { Assert.isTrue(this.initialized, \"template not initialized; call afterPropertiesSet() before using it\"); Assert.notNull(action, \"Callback object must not be null\"); RedisConnectionFactory factory = this.getConnectionFactory(); RedisConnection conn = null; Object var11; try { //enableTransactionSupport 是否支持事务 if (this.enableTransactionSupport) { conn = RedisConnectionUtils.bindConnection(factory, this.enableTransactionSupport); } else { conn = RedisConnectionUtils.getConnection(factory); } //现存的; 目前的; boolean existingConnection = TransactionSynchronizationManager.hasResource(factory); RedisConnection connToUse = this.preProcessConnection(conn, existingConnection); boolean pipelineStatus = connToUse.isPipelined(); if (pipeline &amp;&amp; !pipelineStatus) { connToUse.openPipeline(); } RedisConnection connToExpose = exposeConnection ? connToUse : this.createRedisConnectionProxy(connToUse); T result = action.doInRedis(connToExpose); if (pipeline &amp;&amp; !pipelineStatus) { connToUse.closePipeline(); } var11 = this.postProcessResult(result, connToUse, existingConnection); } finally { RedisConnectionUtils.releaseConnection(conn, factory); } return var11; } public &lt;T&gt; T execute(SessionCallback&lt;T&gt; session) { Assert.isTrue(this.initialized, \"template not initialized; call afterPropertiesSet() before using it\"); Assert.notNull(session, \"Callback object must not be null\"); RedisConnectionFactory factory = this.getConnectionFactory(); RedisConnectionUtils.bindConnection(factory, this.enableTransactionSupport); Object var3; try { var3 = session.execute(this); } finally { RedisConnectionUtils.unbindConnection(factory); } return var3; } //executePipelined 执行管道 public List&lt;Object&gt; executePipelined(SessionCallback&lt;?&gt; session) { return this.executePipelined(session, this.valueSerializer); } public List&lt;Object&gt; executePipelined(final SessionCallback&lt;?&gt; session, final RedisSerializer&lt;?&gt; resultSerializer) { Assert.isTrue(this.initialized, \"template not initialized; call afterPropertiesSet() before using it\"); Assert.notNull(session, \"Callback object must not be null\"); RedisConnectionFactory factory = this.getConnectionFactory(); RedisConnectionUtils.bindConnection(factory, this.enableTransactionSupport); List var4; try { var4 = (List)this.execute(new RedisCallback&lt;List&lt;Object&gt;&gt;() { public List&lt;Object&gt; doInRedis(RedisConnection connection) throws DataAccessException { connection.openPipeline(); boolean pipelinedClosed = false; List var5; try { Object result = RedisTemplate.this.executeSession(session); if (result != null) { throw new InvalidDataAccessApiUsageException(\"Callback cannot return a non-null value as it gets overwritten by the pipeline\"); } List&lt;Object&gt; closePipeline = connection.closePipeline(); pipelinedClosed = true; var5 = RedisTemplate.this.deserializeMixedResults(closePipeline, resultSerializer, RedisTemplate.this.hashKeySerializer, RedisTemplate.this.hashValueSerializer); } finally { if (!pipelinedClosed) { connection.closePipeline(); } } return var5; } }); } finally { RedisConnectionUtils.unbindConnection(factory); } return var4; } public List&lt;Object&gt; executePipelined(RedisCallback&lt;?&gt; action) { return this.executePipelined(action, this.valueSerializer); } public List&lt;Object&gt; executePipelined(final RedisCallback&lt;?&gt; action, final RedisSerializer&lt;?&gt; resultSerializer) { return (List)this.execute(new RedisCallback&lt;List&lt;Object&gt;&gt;() { public List&lt;Object&gt; doInRedis(RedisConnection connection) throws DataAccessException { connection.openPipeline(); boolean pipelinedClosed = false; List var5; try { Object result = action.doInRedis(connection); if (result != null) { throw new InvalidDataAccessApiUsageException(\"Callback cannot return a non-null value as it gets overwritten by the pipeline\"); } List&lt;Object&gt; closePipeline = connection.closePipeline(); pipelinedClosed = true; var5 = RedisTemplate.this.deserializeMixedResults(closePipeline, resultSerializer, RedisTemplate.this.hashKeySerializer, RedisTemplate.this.hashValueSerializer); } finally { if (!pipelinedClosed) { connection.closePipeline(); } } return var5; } }); } public &lt;T&gt; T execute(RedisScript&lt;T&gt; script, List&lt;K&gt; keys, Object... args) { return this.scriptExecutor.execute(script, keys, args); } public &lt;T&gt; T execute(RedisScript&lt;T&gt; script, RedisSerializer&lt;?&gt; argsSerializer, RedisSerializer&lt;T&gt; resultSerializer, List&lt;K&gt; keys, Object... args) { return this.scriptExecutor.execute(script, argsSerializer, resultSerializer, keys, args); } public &lt;T extends Closeable&gt; T executeWithStickyConnection(RedisCallback&lt;T&gt; callback) { Assert.isTrue(this.initialized, \"template not initialized; call afterPropertiesSet() before using it\"); Assert.notNull(callback, \"Callback object must not be null\"); RedisConnectionFactory factory = this.getConnectionFactory(); RedisConnection connection = this.preProcessConnection(RedisConnectionUtils.doGetConnection(factory, true, false, false), false); return (Closeable)callback.doInRedis(connection); } //Session会话 private Object executeSession(SessionCallback&lt;?&gt; session) { return session.execute(this); } //Proxy 代理服务器; 代表权; 代理人，代替物; 委托书; protected RedisConnection createRedisConnectionProxy(RedisConnection pm) { Class&lt;?&gt;[] ifcs = ClassUtils.getAllInterfacesForClass(pm.getClass(), this.getClass().getClassLoader()); return (RedisConnection)Proxy.newProxyInstance(pm.getClass().getClassLoader(), ifcs, new CloseSuppressingInvocationHandler(pm)); } protected RedisConnection preProcessConnection(RedisConnection connection, boolean existingConnection) { return connection; } protected &lt;T&gt; T postProcessResult(T result, RedisConnection conn, boolean existingConnection) { return result; } public boolean isExposeConnection() { return this.exposeConnection; } public void setExposeConnection(boolean exposeConnection) { this.exposeConnection = exposeConnection; } //是否默认序列化 public boolean isEnableDefaultSerializer() { return this.enableDefaultSerializer; } public void setEnableDefaultSerializer(boolean enableDefaultSerializer) { this.enableDefaultSerializer = enableDefaultSerializer; } public RedisSerializer&lt;?&gt; getDefaultSerializer() { return this.defaultSerializer; } public void setDefaultSerializer(RedisSerializer&lt;?&gt; serializer) { this.defaultSerializer = serializer; } public void setKeySerializer(RedisSerializer&lt;?&gt; serializer) { this.keySerializer = serializer; } public RedisSerializer&lt;?&gt; getKeySerializer() { return this.keySerializer; } public void setValueSerializer(RedisSerializer&lt;?&gt; serializer) { this.valueSerializer = serializer; } public RedisSerializer&lt;?&gt; getValueSerializer() { return this.valueSerializer; } public RedisSerializer&lt;?&gt; getHashKeySerializer() { return this.hashKeySerializer; } public void setHashKeySerializer(RedisSerializer&lt;?&gt; hashKeySerializer) { this.hashKeySerializer = hashKeySerializer; } public RedisSerializer&lt;?&gt; getHashValueSerializer() { return this.hashValueSerializer; } public void setHashValueSerializer(RedisSerializer&lt;?&gt; hashValueSerializer) { this.hashValueSerializer = hashValueSerializer; } public RedisSerializer&lt;String&gt; getStringSerializer() { return this.stringSerializer; } public void setStringSerializer(RedisSerializer&lt;String&gt; stringSerializer) { this.stringSerializer = stringSerializer; } public void setScriptExecutor(ScriptExecutor&lt;K&gt; scriptExecutor) { this.scriptExecutor = scriptExecutor; } private byte[] rawKey(Object key) { Assert.notNull(key, \"non null key required\"); return this.keySerializer == null &amp;&amp; key instanceof byte[] ? (byte[])((byte[])key) : this.keySerializer.serialize(key); } private byte[] rawString(String key) { return this.stringSerializer.serialize(key); } private byte[] rawValue(Object value) { return this.valueSerializer == null &amp;&amp; value instanceof byte[] ? (byte[])((byte[])value) : this.valueSerializer.serialize(value); } private byte[][] rawKeys(Collection&lt;K&gt; keys) { byte[][] rawKeys = new byte[keys.size()][]; int i = 0; Object key; for(Iterator var4 = keys.iterator(); var4.hasNext(); rawKeys[i++] = this.rawKey(key)) { key = var4.next(); } return rawKeys; } //deserializeKey 反序列化 private K deserializeKey(byte[] value) { return this.keySerializer != null ? this.keySerializer.deserialize(value) : value; } private List&lt;Object&gt; deserializeMixedResults(List&lt;Object&gt; rawValues, RedisSerializer valueSerializer, RedisSerializer hashKeySerializer, RedisSerializer hashValueSerializer) { if (rawValues == null) { return null; } else { List&lt;Object&gt; values = new ArrayList(); Iterator var6 = rawValues.iterator(); while(true) { while(var6.hasNext()) { Object rawValue = var6.next(); if (rawValue instanceof byte[] &amp;&amp; valueSerializer != null) { values.add(valueSerializer.deserialize((byte[])((byte[])rawValue))); } else if (rawValue instanceof List) { values.add(this.deserializeMixedResults((List)rawValue, valueSerializer, hashKeySerializer, hashValueSerializer)); } else if (rawValue instanceof Set &amp;&amp; !((Set)rawValue).isEmpty()) { values.add(this.deserializeSet((Set)rawValue, valueSerializer)); } else if (rawValue instanceof Map &amp;&amp; !((Map)rawValue).isEmpty() &amp;&amp; ((Map)rawValue).values().iterator().next() instanceof byte[]) { values.add(SerializationUtils.deserialize((Map)rawValue, hashKeySerializer, hashValueSerializer)); } else { values.add(rawValue); } } return values; } } } private Set&lt;?&gt; deserializeSet(Set rawSet, RedisSerializer valueSerializer) { if (rawSet.isEmpty()) { return rawSet; } else { Object setValue = rawSet.iterator().next(); if (setValue instanceof byte[] &amp;&amp; valueSerializer != null) { return SerializationUtils.deserialize(rawSet, valueSerializer); } else { return setValue instanceof Tuple ? this.convertTupleValues(rawSet, valueSerializer) : rawSet; } } } //拼装数组值 private Set&lt;TypedTuple&lt;V&gt;&gt; convertTupleValues(Set&lt;Tuple&gt; rawValues, RedisSerializer valueSerializer) { Set&lt;TypedTuple&lt;V&gt;&gt; set = new LinkedHashSet(rawValues.size()); Tuple rawValue; Object value; for(Iterator var4 = rawValues.iterator(); var4.hasNext(); set.add(new DefaultTypedTuple(value, rawValue.getScore()))) { rawValue = (Tuple)var4.next(); value = rawValue.getValue(); if (valueSerializer != null) { value = valueSerializer.deserialize(rawValue.getValue()); } } return set; } public List&lt;Object&gt; exec() { List&lt;Object&gt; results = this.execRaw(); return this.getConnectionFactory().getConvertPipelineAndTxResults() ? this.deserializeMixedResults(results, this.valueSerializer, this.hashKeySerializer, this.hashValueSerializer) : results; } public List&lt;Object&gt; exec(RedisSerializer&lt;?&gt; valueSerializer) { return this.deserializeMixedResults(this.execRaw(), valueSerializer, valueSerializer, valueSerializer); } protected List&lt;Object&gt; execRaw() { return (List)this.execute(new RedisCallback&lt;List&lt;Object&gt;&gt;() { public List&lt;Object&gt; doInRedis(RedisConnection connection) throws DataAccessException { return connection.exec(); } }); } //删除，根据键删除值 public void delete(K key) { final byte[] rawKey = this.rawKey(key); this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) { connection.del(new byte[][]{rawKey}); return null; } }, true); } //删除,根据键的集合，批量删除值 public void delete(Collection&lt;K&gt; keys) { if (!CollectionUtils.isEmpty(keys)) { final byte[][] rawKeys = this.rawKeys(keys); this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) { connection.del(rawKeys); return null; } }, true); } } //是否含有指定的键 public Boolean hasKey(K key) { final byte[] rawKey = this.rawKey(key); return (Boolean)this.execute(new RedisCallback&lt;Boolean&gt;() { public Boolean doInRedis(RedisConnection connection) { return connection.exists(rawKey); } }, true); } //缓存是否过期 //expire 期满; 文件、协议等（因到期而）失效; 断气; 逝世; public Boolean expire(K key, final long timeout, final TimeUnit unit) { final byte[] rawKey = this.rawKey(key); final long rawTimeout = TimeoutUtils.toMillis(timeout, unit); return (Boolean)this.execute(new RedisCallback&lt;Boolean&gt;() { public Boolean doInRedis(RedisConnection connection) { try { return connection.pExpire(rawKey, rawTimeout); } catch (Exception var3) { return connection.expire(rawKey, TimeoutUtils.toSeconds(timeout, unit)); } } }, true); } public Boolean expireAt(K key, final Date date) { final byte[] rawKey = this.rawKey(key); return (Boolean)this.execute(new RedisCallback&lt;Boolean&gt;() { public Boolean doInRedis(RedisConnection connection) { try { return connection.pExpireAt(rawKey, date.getTime()); } catch (Exception var3) { return connection.expireAt(rawKey, date.getTime() / 1000L); } } }, true); } //订阅发布 public void convertAndSend(String channel, Object message) { Assert.hasText(channel, \"a non-empty channel is required\"); final byte[] rawChannel = this.rawString(channel); final byte[] rawMessage = this.rawValue(message); this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) { connection.publish(rawChannel, rawMessage); return null; } }, true); } public Long getExpire(K key) { final byte[] rawKey = this.rawKey(key); return (Long)this.execute(new RedisCallback&lt;Long&gt;() { public Long doInRedis(RedisConnection connection) { return connection.ttl(rawKey); } }, true); } public Long getExpire(K key, final TimeUnit timeUnit) { final byte[] rawKey = this.rawKey(key); return (Long)this.execute(new RedisCallback&lt;Long&gt;() { public Long doInRedis(RedisConnection connection) { try { return connection.pTtl(rawKey, timeUnit); } catch (Exception var3) { return connection.ttl(rawKey, timeUnit); } } }, true); } public Set&lt;K&gt; keys(K pattern) { final byte[] rawKey = this.rawKey(pattern); Set&lt;byte[]&gt; rawKeys = (Set)this.execute(new RedisCallback&lt;Set&lt;byte[]&gt;&gt;() { public Set&lt;byte[]&gt; doInRedis(RedisConnection connection) { return connection.keys(rawKey); } }, true); return this.keySerializer != null ? SerializationUtils.deserialize(rawKeys, this.keySerializer) : rawKeys; } //持久化 //persist：坚持; 存留; 固执; 继续存在; public Boolean persist(K key) { final byte[] rawKey = this.rawKey(key); return (Boolean)this.execute(new RedisCallback&lt;Boolean&gt;() { public Boolean doInRedis(RedisConnection connection) { return connection.persist(rawKey); } }, true); } //move移动 public Boolean move(K key, final int dbIndex) { final byte[] rawKey = this.rawKey(key); return (Boolean)this.execute(new RedisCallback&lt;Boolean&gt;() { public Boolean doInRedis(RedisConnection connection) { return connection.move(rawKey, dbIndex); } }, true); } //获取随机key值 public K randomKey() { byte[] rawKey = (byte[])this.execute(new RedisCallback&lt;byte[]&gt;() { public byte[] doInRedis(RedisConnection connection) { return connection.randomKey(); } }, true); return this.deserializeKey(rawKey); } //key值重命名 public void rename(K oldKey, K newKey) { final byte[] rawOldKey = this.rawKey(oldKey); final byte[] rawNewKey = this.rawKey(newKey); this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) { connection.rename(rawOldKey, rawNewKey); return null; } }, true); } //如果没有就重命名 //Absent 缺席的，不在场的; 缺少的，缺乏的; 不在意的，茫然的; public Boolean renameIfAbsent(K oldKey, K newKey) { final byte[] rawOldKey = this.rawKey(oldKey); final byte[] rawNewKey = this.rawKey(newKey); return (Boolean)this.execute(new RedisCallback&lt;Boolean&gt;() { public Boolean doInRedis(RedisConnection connection) { return connection.renameNX(rawOldKey, rawNewKey); } }, true); } //DataType类型的 类型 public DataType type(K key) { final byte[] rawKey = this.rawKey(key); return (DataType)this.execute(new RedisCallback&lt;DataType&gt;() { public DataType doInRedis(RedisConnection connection) { return connection.type(rawKey); } }, true); } public byte[] dump(K key) { final byte[] rawKey = this.rawKey(key); return (byte[])this.execute(new RedisCallback&lt;byte[]&gt;() { public byte[] doInRedis(RedisConnection connection) { return connection.dump(rawKey); } }, true); } //restore 修复; 归还; 交还; 使恢复; public void restore(K key, final byte[] value, long timeToLive, TimeUnit unit) { final byte[] rawKey = this.rawKey(key); final long rawTimeout = TimeoutUtils.toMillis(timeToLive, unit); this.execute(new RedisCallback&lt;Object&gt;() { public Boolean doInRedis(RedisConnection connection) { connection.restore(rawKey, rawTimeout, value); return null; } }, true); } //multi 前缀 public void multi() { this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) throws DataAccessException { connection.multi(); return null; } }, true); } //discard 丢弃，抛弃; 解雇; 出牌; public void discard() { this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) throws DataAccessException { connection.discard(); return null; } }, true); } //watch 注视，注意; 看守，监视; 守候（机会等）; 密切注意 public void watch(K key) { final byte[] rawKey = this.rawKey(key); this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) { connection.watch(new byte[][]{rawKey}); return null; } }, true); } public void watch(Collection&lt;K&gt; keys) { final byte[][] rawKeys = this.rawKeys(keys); this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) { connection.watch(rawKeys); return null; } }, true); } public void unwatch() { this.execute(new RedisCallback&lt;Object&gt;() { public Object doInRedis(RedisConnection connection) throws DataAccessException { connection.unwatch(); return null; } }, true); } //sort 排序 public List&lt;V&gt; sort(SortQuery&lt;K&gt; query) { return this.sort(query, this.valueSerializer); } public &lt;T&gt; List&lt;T&gt; sort(SortQuery&lt;K&gt; query, RedisSerializer&lt;T&gt; resultSerializer) { final byte[] rawKey = this.rawKey(query.getKey()); final SortParameters params = QueryUtils.convertQuery(query, this.stringSerializer); List&lt;byte[]&gt; vals = (List)this.execute(new RedisCallback&lt;List&lt;byte[]&gt;&gt;() { public List&lt;byte[]&gt; doInRedis(RedisConnection connection) throws DataAccessException { return connection.sort(rawKey, params); } }, true); return SerializationUtils.deserialize(vals, resultSerializer); } public &lt;T&gt; List&lt;T&gt; sort(SortQuery&lt;K&gt; query, BulkMapper&lt;T, V&gt; bulkMapper) { return this.sort(query, bulkMapper, this.valueSerializer); } public &lt;T, S&gt; List&lt;T&gt; sort(SortQuery&lt;K&gt; query, BulkMapper&lt;T, S&gt; bulkMapper, RedisSerializer&lt;S&gt; resultSerializer) { List&lt;S&gt; values = this.sort(query, resultSerializer); if (values != null &amp;&amp; !values.isEmpty()) { int bulkSize = query.getGetPattern().size(); List&lt;T&gt; result = new ArrayList(values.size() / bulkSize + 1); List&lt;S&gt; bulk = new ArrayList(bulkSize); Iterator var8 = values.iterator(); while(var8.hasNext()) { S s = var8.next(); bulk.add(s); if (bulk.size() == bulkSize) { result.add(bulkMapper.mapBulk(Collections.unmodifiableList(bulk))); bulk = new ArrayList(bulkSize); } } return result; } else { return Collections.emptyList(); } } public Long sort(SortQuery&lt;K&gt; query, K storeKey) { final byte[] rawStoreKey = this.rawKey(storeKey); final byte[] rawKey = this.rawKey(query.getKey()); final SortParameters params = QueryUtils.convertQuery(query, this.stringSerializer); return (Long)this.execute(new RedisCallback&lt;Long&gt;() { public Long doInRedis(RedisConnection connection) throws DataAccessException { return connection.sort(rawKey, params, rawStoreKey); } }, true); } //BoundValueOperations暂时不知道什么意思,可能是操作边界值 //bound n界限，限制; 跃起; （球等的） 反跳 ,v缚; 给…划界，限制; 使弹回，使跳跃; public BoundValueOperations&lt;K, V&gt; boundValueOps(K key) { return new DefaultBoundValueOperations(key, this); } //操作值,描述具有简单值的条目 public ValueOperations&lt;K, V&gt; opsForValue() { if (this.valueOps == null) { this.valueOps = new DefaultValueOperations(this); } return this.valueOps; } //操作集合,操作具有list值的条目 public ListOperations&lt;K, V&gt; opsForList() { if (this.listOps == null) { this.listOps = new DefaultListOperations(this); } return this.listOps; } //以绑定指定key的方式，操作具有list的条目 public BoundListOperations&lt;K, V&gt; boundListOps(K key) { return new DefaultBoundListOperations(key, this); } //以绑定指定key的方式，操作具有set的条目 public BoundSetOperations&lt;K, V&gt; boundSetOps(K key) { return new DefaultBoundSetOperations(key, this); } //操作具有set值的条目 public SetOperations&lt;K, V&gt; opsForSet() { if (this.setOps == null) { this.setOps = new DefaultSetOperations(this); } return this.setOps; } //以绑定指定key的方式，操作具有ZSet（排序的set）的条目 public BoundZSetOperations&lt;K, V&gt; boundZSetOps(K key) { return new DefaultBoundZSetOperations(key, this); } //操作具有ZSet值（排序的set）的条目 public ZSetOperations&lt;K, V&gt; opsForZSet() { if (this.zSetOps == null) { this.zSetOps = new DefaultZSetOperations(this); } return this.zSetOps; } //Geospatial 键操作 public GeoOperations&lt;K, V&gt; opsForGeo() { if (this.geoOps == null) { this.geoOps = new DefaultGeoOperations(this); } return this.geoOps; } //Redis Geospatial 键绑定操作 public BoundGeoOperations&lt;K, V&gt; boundGeoOps(K key) { return new DefaultBoundGeoOperations(key, this); } //操作Redis HyperLogLog类型数据，比如：pfadd，pfcount，... public HyperLogLogOperations&lt;K, V&gt; opsForHyperLogLog() { if (this.hllOps == null) { this.hllOps = new DefaultHyperLogLogOperations(this); } return this.hllOps; } //Redis Hash键绑定操作 public &lt;HK, HV&gt; BoundHashOperations&lt;K, HK, HV&gt; boundHashOps(K key) { return new DefaultBoundHashOperations(key, this); } //操作Redis Hash类型数据 public &lt;HK, HV&gt; HashOperations&lt;K, HK, HV&gt; opsForHash() { return new DefaultHashOperations(this); } //Cluster 群操作 public ClusterOperations&lt;K, V&gt; opsForCluster() { return new DefaultClusterOperations(this); } public void killClient(final String host, final int port) { this.execute(new RedisCallback&lt;Void&gt;() { public Void doInRedis(RedisConnection connection) throws DataAccessException { connection.killClient(host, port); return null; } }); } //获取redis客户端的集合 public List&lt;RedisClientInfo&gt; getClientList() { return (List)this.execute(new RedisCallback&lt;List&lt;RedisClientInfo&gt;&gt;() { public List&lt;RedisClientInfo&gt; doInRedis(RedisConnection connection) throws DataAccessException { return connection.getClientList(); } }); } //SLAVEOF 命令用于在 Redis 运行时动态地修改复制(replication)功能的行为 public void slaveOf(final String host, final int port) { this.execute(new RedisCallback&lt;Void&gt;() { public Void doInRedis(RedisConnection connection) throws DataAccessException { connection.slaveOf(host, port); return null; } }); } public void slaveOfNoOne() { this.execute(new RedisCallback&lt;Void&gt;() { public Void doInRedis(RedisConnection connection) throws DataAccessException { connection.slaveOfNoOne(); return null; } }); } public void setEnableTransactionSupport(boolean enableTransactionSupport) { this.enableTransactionSupport = enableTransactionSupport; } public void setBeanClassLoader(ClassLoader classLoader) { this.classLoader = classLoader; }}","link":"/2019/08/13/SpringBoot整合Redis/"}],"tags":[{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"live2d","slug":"live2d","link":"/tags/live2d/"},{"name":"安装","slug":"安装","link":"/tags/安装/"},{"name":"故障","slug":"故障","link":"/tags/故障/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"springboot","slug":"springboot","link":"/tags/springboot/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"基础","slug":"基础","link":"/tags/基础/"},{"name":"位运算","slug":"位运算","link":"/tags/位运算/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"模板","slug":"模板","link":"/tags/模板/"}],"categories":[{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"},{"name":"GIT学习","slug":"GIT学习","link":"/categories/GIT学习/"},{"name":"开发问题记录","slug":"开发问题记录","link":"/categories/开发问题记录/"}]}